{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Imagery Classification with NeurOS\n",
    "\n",
    "This notebook demonstrates how to build a motor imagery BCI system using NeurOS. Motor imagery involves imagining movement (e.g., left/right hand) which produces distinct patterns in brain signals.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Setting up a BCI pipeline for motor imagery\n",
    "- Training an EEGNet model on synthetic motor imagery data\n",
    "- Evaluating model performance\n",
    "- Saving models to the registry\n",
    "- Real-time classification simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install neuros if needed\n",
    "# !pip install -e ..\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuros.models import EEGNetModel, ModelRegistry\n",
    "from neuros.pipeline import Pipeline\n",
    "from neuros.drivers import MockDriver\n",
    "from neuros.processing.filters import BandpassFilter\n",
    "from neuros.processing.feature_extraction import BandPowerExtractor\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Motor Imagery Data\n",
    "\n",
    "For this demo, we'll create synthetic EEG data that mimics motor imagery patterns:\n",
    "- **Class 0 (Rest):** Baseline activity\n",
    "- **Class 1 (Left Hand):** Enhanced mu rhythm (8-12 Hz) over left motor cortex\n",
    "- **Class 2 (Right Hand):** Enhanced mu rhythm over right motor cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_motor_imagery_data(n_samples=300, n_channels=8, n_timepoints=250, fs=250.0):\n",
    "    \"\"\"\n",
    "    Generate synthetic motor imagery EEG data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_samples : int\n",
    "        Number of trials\n",
    "    n_channels : int\n",
    "        Number of EEG channels\n",
    "    n_timepoints : int\n",
    "        Number of time points per trial (1 second at 250 Hz)\n",
    "    fs : float\n",
    "        Sampling frequency in Hz\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X : np.ndarray\n",
    "        EEG data of shape (n_samples, n_channels, n_timepoints)\n",
    "    y : np.ndarray\n",
    "        Labels (0=rest, 1=left hand, 2=right hand)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    t = np.arange(n_timepoints) / fs\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Randomly choose class\n",
    "        label = np.random.randint(0, 3)\n",
    "        \n",
    "        # Base noise\n",
    "        trial = np.random.randn(n_channels, n_timepoints) * 0.5\n",
    "        \n",
    "        if label == 1:  # Left hand imagery\n",
    "            # Add mu rhythm (10 Hz) to left motor cortex (channels 0-3)\n",
    "            mu_signal = 2.0 * np.sin(2 * np.pi * 10 * t)\n",
    "            trial[:4, :] += mu_signal\n",
    "            \n",
    "        elif label == 2:  # Right hand imagery\n",
    "            # Add mu rhythm to right motor cortex (channels 4-7)\n",
    "            mu_signal = 2.0 * np.sin(2 * np.pi * 10 * t)\n",
    "            trial[4:, :] += mu_signal\n",
    "        \n",
    "        # Add some 1/f noise\n",
    "        for ch in range(n_channels):\n",
    "            freqs = np.fft.rfftfreq(n_timepoints, 1/fs)\n",
    "            fft_signal = np.fft.rfft(trial[ch])\n",
    "            # 1/f spectrum\n",
    "            fft_signal *= 1 / (freqs + 1)**0.5\n",
    "            trial[ch] = np.fft.irfft(fft_signal, n=n_timepoints)\n",
    "        \n",
    "        X.append(trial)\n",
    "        y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generate dataset\n",
    "print(\"Generating synthetic motor imagery data...\")\n",
    "X, y = generate_motor_imagery_data(n_samples=300)\n",
    "print(f\"✓ Generated {len(X)} trials\")\n",
    "print(f\"  Shape: {X.shape} (samples, channels, timepoints)\")\n",
    "print(f\"  Labels: {np.bincount(y)} trials per class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8))\n",
    "class_names = ['Rest', 'Left Hand', 'Right Hand']\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "for cls in range(3):\n",
    "    # Find first trial of this class\n",
    "    idx = np.where(y == cls)[0][0]\n",
    "    \n",
    "    # Plot all channels\n",
    "    for ch in range(X.shape[1]):\n",
    "        axes[cls].plot(X[idx, ch, :] + ch * 3, alpha=0.7, linewidth=0.8)\n",
    "    \n",
    "    axes[cls].set_title(f\"Class {cls}: {class_names[cls]}\", fontsize=12, fontweight='bold')\n",
    "    axes[cls].set_ylabel('Channel (offset)')\n",
    "    axes[cls].set_ylim(-2, X.shape[1] * 3)\n",
    "\n",
    "axes[2].set_xlabel('Time (samples)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Left hand trials show enhanced activity in channels 0-3\")\n",
    "print(\"      Right hand trials show enhanced activity in channels 4-7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} trials\")\n",
    "print(f\"Test set: {len(X_test)} trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train EEGNet Model\n",
    "\n",
    "EEGNet is a compact convolutional neural network specifically designed for EEG classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EEGNet model\n",
    "model = EEGNetModel(\n",
    "    n_channels=8,\n",
    "    n_classes=3,\n",
    "    n_timepoints=250,\n",
    "    dropout=0.5,\n",
    ")\n",
    "\n",
    "print(\"Training EEGNet model...\")\n",
    "print(\"(This may take 1-2 minutes)\\n\")\n",
    "\n",
    "# Train model\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model to Registry\n",
    "\n",
    "NeurOS includes a model registry for managing trained models with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize registry\n",
    "registry = ModelRegistry()\n",
    "\n",
    "# Save model with metadata\n",
    "metadata = registry.save(\n",
    "    model,\n",
    "    name=\"motor_imagery_eegnet\",\n",
    "    version=\"1.0.0\",\n",
    "    metrics={\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"n_train_samples\": len(X_train),\n",
    "        \"n_test_samples\": len(X_test),\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"n_channels\": 8,\n",
    "        \"n_classes\": 3,\n",
    "        \"dropout\": 0.5,\n",
    "    },\n",
    "    training_info={\n",
    "        \"dataset\": \"synthetic_motor_imagery\",\n",
    "        \"n_epochs\": 100,\n",
    "    },\n",
    "    tags=[\"motor-imagery\", \"eegnet\", \"demo\"],\n",
    ")\n",
    "\n",
    "print(f\"✓ Model saved: {metadata.name} v{metadata.version}\")\n",
    "print(f\"  Location: {metadata.file_path}\")\n",
    "print(f\"  Accuracy: {metadata.metrics['accuracy']:.2%}\")\n",
    "print(f\"  Tags: {', '.join(metadata.tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Model from Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = registry.load(\"motor_imagery_eegnet\", version=\"1.0.0\")\n",
    "\n",
    "# Test that it works\n",
    "test_predictions = loaded_model.predict(X_test[:5])\n",
    "print(f\"✓ Model loaded successfully\")\n",
    "print(f\"  Test predictions on 5 samples: {test_predictions}\")\n",
    "print(f\"  True labels: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-Time Classification Simulation\n",
    "\n",
    "Simulate real-time motor imagery classification using the mock driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Create pipeline with trained model\n",
    "pipeline = Pipeline(\n",
    "    driver=MockDriver(sampling_rate=250.0, channels=8),\n",
    "    model=loaded_model,\n",
    "    fs=250.0,\n",
    "    bands={\n",
    "        \"mu\": (8, 12),     # Mu rhythm for motor imagery\n",
    "        \"beta\": (12, 30),  # Beta band\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Running real-time pipeline for 3 seconds...\")\n",
    "print(\"(Using mock driver for demonstration)\\n\")\n",
    "\n",
    "# Run pipeline\n",
    "metrics = await pipeline.run(duration=3.0)\n",
    "\n",
    "print(\"\\n✓ Pipeline complete!\")\n",
    "print(f\"  Throughput: {metrics['throughput']:.1f} samples/sec\")\n",
    "print(f\"  Mean latency: {metrics['mean_latency']*1000:.2f} ms\")\n",
    "print(f\"  Total samples: {metrics['samples']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "Now that you've built a motor imagery BCI:\n",
    "\n",
    "1. **Try with real hardware:** Replace `MockDriver` with `BrainFlowDriver` for OpenBCI, Emotiv, etc.\n",
    "2. **Experiment with models:** Try `TransformerModel`, `CNNModel`, or `RandomForestModel`\n",
    "3. **Tune hyperparameters:** Adjust learning rate, dropout, number of epochs\n",
    "4. **Real-time feedback:** Add visual/audio feedback based on predictions\n",
    "5. **Multi-modal fusion:** Combine EEG with EMG, video, or other modalities\n",
    "\n",
    "See other notebooks:\n",
    "- `02_multimodal_fusion.ipynb` - Combine multiple data sources\n",
    "- `03_p300_speller.ipynb` - Build a brain-controlled keyboard\n",
    "- `04_real_hardware_setup.ipynb` - Connect to physical BCI devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models in registry\n",
    "all_models = registry.list_models()\n",
    "print(f\"\\nModels in registry: {len(all_models)}\")\n",
    "for m in all_models:\n",
    "    acc = m.metrics.get('accuracy', 0)\n",
    "    print(f\"  - {m.name} v{m.version}: {acc:.2%} accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
