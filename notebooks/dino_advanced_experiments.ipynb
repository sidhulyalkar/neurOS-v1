{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50ce759",
   "metadata": {},
   "source": [
    "# Advanced DINOv3 Experiments in neurOS\n",
    "\n",
    "In this notebook we go beyond basic segmentation to explore two\n",
    "additional settings:\n",
    "\n",
    "1. **Registration via feature matching.**  We generate pairs of images\n",
    "   where the second is a shifted version of the first.  By extracting\n",
    "   patch features with DINOv3 and computing cosine similarities between\n",
    "   patches, we can estimate the translation between the two images.\n",
    "2. **Crossâ€‘modality generalisation.**  We train a segmentation model on\n",
    "   one modality (e.g. electron microscopy) and test it on another\n",
    "   (histology) to assess the robustness of the learned features.\n",
    "\n",
    "These experiments are synthetic but illustrate how to use the\n",
    "``neuros`` DINOv3 plugin and the ``feature_matching`` utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31261263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from neuros.plugins.cv.dinov3_backbone import DINOv3Backbone\n",
    "from neuros.plugins.cv.feature_matching import patch_correlation, estimate_translation\n",
    "\n",
    "def generate_synthetic_dataset(num_images: int, size: int = 128, mode: str = \"em\"):\n",
    "    '''Generate synthetic datasets for different modalities.\n",
    "\n",
    "    Modes:\n",
    "        em  - random noise with bright spots (neurites)\n",
    "        mri - smooth gradient with circular lesion\n",
    "        histology - texture with darker nucleus region\n",
    "    '''\n",
    "    images = []\n",
    "    masks = []\n",
    "    rng = np.random.default_rng(123)\n",
    "    for _ in range(num_images):\n",
    "        if mode == \"em\":\n",
    "            img = rng.normal(loc=0.5, scale=0.15, size=(size, size, 1)).clip(0, 1)\n",
    "            mask = np.zeros((size, size), dtype=np.int32)\n",
    "            for _ in range(rng.integers(3, 7)):\n",
    "                cx, cy = rng.integers(0, size, size=2)\n",
    "                r = rng.integers(size//20, size//10)\n",
    "                Y, X = np.ogrid[:size, :size]\n",
    "                circle = (X - cx)**2 + (Y - cy)**2 <= r**2\n",
    "                mask[circle] = 1\n",
    "                img[circle] += 0.5\n",
    "            img = img.clip(0, 1)\n",
    "            img_rgb = np.repeat(img, 3, axis=2)\n",
    "        elif mode == \"mri\":\n",
    "            x = np.linspace(-1, 1, size)\n",
    "            y = np.linspace(-1, 1, size)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            img = 0.5 + 0.5 * (X + Y) / 2\n",
    "            mask = ((X**2 + Y**2) < 0.2**2).astype(np.int32)\n",
    "            img[mask == 1] = 1.0\n",
    "            img_rgb = np.repeat(img[:, :, None], 3, axis=2)\n",
    "        elif mode == \"histology\":\n",
    "            base = rng.uniform(0.8, 1.0, size=(size, size, 3))\n",
    "            noise = rng.normal(0, 0.05, size=(size, size, 3))\n",
    "            img_rgb = (base + noise).clip(0, 1)\n",
    "            mask = np.zeros((size, size), dtype=np.int32)\n",
    "            cx, cy = rng.integers(size//4, 3*size//4, size=2)\n",
    "            r = size // 6\n",
    "            Y, X = np.ogrid[:size, :size]\n",
    "            nucleus = (X - cx)**2 + (Y - cy)**2 <= r**2\n",
    "            mask[nucleus] = 1\n",
    "            img_rgb[nucleus] -= 0.4\n",
    "            img_rgb = img_rgb.clip(0, 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "        images.append((img_rgb * 255).astype(np.uint8))\n",
    "        masks.append(mask)\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def flatten_dataset(images, masks, backbone):\n",
    "    '''Flatten a dataset into patch features and labels for segmentation.'''\n",
    "    all_feats = []\n",
    "    all_labels = []\n",
    "    for img, mask in zip(images, masks):\n",
    "        pf = backbone.embed([img])[0]\n",
    "        gs = backbone.grid_size\n",
    "        ps = backbone.patch_size\n",
    "        mask_crop = mask[:gs*ps, :gs*ps]\n",
    "        patch_mask = mask_crop.reshape(gs, ps, gs, ps)\n",
    "        labels = (patch_mask.sum(axis=(1, 3)) > (ps*ps/2)).astype(np.int32)\n",
    "        all_feats.append(pf)\n",
    "        all_labels.append(labels.flatten())\n",
    "    return np.concatenate(all_feats), np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "def train_segmentation(backbone_id, train_mode, test_mode):\n",
    "    '''Train on one modality and test on another.'''\n",
    "    backbone = DINOv3Backbone(model_id=backbone_id)\n",
    "    # Generate data\n",
    "    images_train, masks_train = generate_synthetic_dataset(10, mode=train_mode)\n",
    "    images_test, masks_test = generate_synthetic_dataset(5, mode=test_mode)\n",
    "    X_train, y_train = flatten_dataset(images_train, masks_train, backbone)\n",
    "    X_test, y_test = flatten_dataset(images_test, masks_test, backbone)\n",
    "    # Handle single-class case\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        majority = y_train[0]\n",
    "        preds = np.full_like(y_test, majority)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        clf = LogisticRegression(max_iter=300)\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "    return acc, f1\n",
    "\n",
    "\n",
    "def evaluate_registration(backbone_id, mode, shift=(1, 1)):\n",
    "    '''Generate a pair of images with a known shift and estimate translation.'''\n",
    "    backbone = DINOv3Backbone(model_id=backbone_id)\n",
    "    images, _ = generate_synthetic_dataset(1, mode=mode)\n",
    "    img = images[0]\n",
    "    dy, dx = shift\n",
    "    # Create a shifted copy by rolling the image; fill wrap-around with zeros\n",
    "    shifted = np.roll(img, shift=(dy*backbone.patch_size, dx*backbone.patch_size), axis=(0, 1))\n",
    "    if dy > 0:\n",
    "        shifted[:dy*backbone.patch_size, :] = 0\n",
    "    elif dy < 0:\n",
    "        shifted[dy*backbone.patch_size:, :] = 0\n",
    "    if dx > 0:\n",
    "        shifted[:, :dx*backbone.patch_size] = 0\n",
    "    elif dx < 0:\n",
    "        shifted[:, dx*backbone.patch_size:] = 0\n",
    "    # Extract features\n",
    "    pf_a = backbone.embed([img])[0]\n",
    "    pf_b = backbone.embed([shifted])[0]\n",
    "    sim = patch_correlation(pf_a, pf_b)\n",
    "    est_dy, est_dx = estimate_translation(sim, backbone.grid_size)\n",
    "    return (dy, dx), (est_dy, est_dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29cbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation across modalities\n",
    "results_seg = {}\n",
    "modalities = [\"em\", \"mri\", \"histology\"]\n",
    "models = {\"CNX-Tiny\": \"cnx-tiny\", \"ViT-Large\": \"vit-large\"}\n",
    "for train_mod in modalities:\n",
    "    results_seg[train_mod] = {}\n",
    "    for test_mod in modalities:\n",
    "        results_seg[train_mod][test_mod] = {}\n",
    "        for name, model_id in models.items():\n",
    "            acc, f1 = train_segmentation(model_id, train_mod, test_mod)\n",
    "            results_seg[train_mod][test_mod][name] = (acc, f1)\n",
    "            print(f\"{name} train {train_mod} -> test {test_mod}: acc={acc:.3f}, f1={f1:.3f}\")\n",
    "results_seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e82746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registration evaluation\n",
    "results_reg = {}\n",
    "modalities = [\"em\", \"mri\", \"histology\"]\n",
    "shifts = [(1, 1), (0, 2), (-2, -1)]\n",
    "for mode in modalities:\n",
    "    results_reg[mode] = {}\n",
    "    for name, model_id in models.items():\n",
    "        # Evaluate three different shifts and average absolute error\n",
    "        errors = []\n",
    "        for shift in shifts:\n",
    "            true_shift, est_shift = evaluate_registration(model_id, mode, shift=shift)\n",
    "            err = (abs(true_shift[0] - est_shift[0]) + abs(true_shift[1] - est_shift[1]))\n",
    "            errors.append(err)\n",
    "            print(f\"{name} on {mode} shift {true_shift} -> estimated {est_shift}\")\n",
    "        mean_error = float(np.mean(errors))\n",
    "        results_reg[mode][name] = mean_error\n",
    "    print()\n",
    "results_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise segmentation cross-modality accuracy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Build matrices for accuracy and F1 for CNX-Tiny and ViT-Large\n",
    "metrics = {\"accuracy\": 0, \"f1\": 1}\n",
    "for metric_name, idx in metrics.items():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for j, (model_name, _) in enumerate(models.items()):\n",
    "        data = []\n",
    "        for train_mod in modalities:\n",
    "            row = []\n",
    "            for test_mod in modalities:\n",
    "                row.append(results_seg[train_mod][test_mod][model_name][idx])\n",
    "            data.append(row)\n",
    "        data = np.array(data)\n",
    "        ax = axes[j]\n",
    "        im = ax.imshow(data, vmin=0, vmax=1, cmap=\"viridis\")\n",
    "        ax.set_xticks(range(len(modalities)))\n",
    "        ax.set_xticklabels(modalities)\n",
    "        ax.set_yticks(range(len(modalities)))\n",
    "        ax.set_yticklabels(modalities)\n",
    "        ax.set_xlabel(\"Test modality\")\n",
    "        ax.set_ylabel(\"Train modality\")\n",
    "        ax.set_title(f\"{metric_name.capitalize()} - {model_name}\")\n",
    "        for (i, k), val in np.ndenumerate(data):\n",
    "            ax.text(k, i, f\"{val:.2f}\", ha='center', va='center', color='white' if val < 0.5 else 'black')\n",
    "    fig.suptitle(f\"Cross-modality {metric_name.capitalize()}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot registration errors\n",
    "import matplotlib.pyplot as plt\n",
    "labels = modalities\n",
    "cnx_errors = [results_reg[mod][\"CNX-Tiny\"] for mod in modalities]\n",
    "vit_errors = [results_reg[mod][\"ViT-Large\"] for mod in modalities]\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.bar(np.arange(len(labels)) - width/2, cnx_errors, width, label='CNX-Tiny')\n",
    "ax.bar(np.arange(len(labels)) + width/2, vit_errors, width, label='ViT-Large')\n",
    "ax.set_xticks(np.arange(len(labels)))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Mean absolute patch shift error')\n",
    "ax.set_title('Registration performance across modalities')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
