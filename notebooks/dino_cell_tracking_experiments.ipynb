{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fe70c5",
   "metadata": {},
   "source": [
    "# DINOv3 Evaluation on Cell Tracking Challenge\n",
    "\n",
    "The **Cell Tracking Challenge** fosters the development of robust cell segmentation and tracking algorithms. Since its launch in 2012 it has organised several benchmarking events, offering segmentation‑and‑tracking as well as segmentation‑only tasks on both 2D+time and 3D+time datasets【195398378225483†L47-L68】. The challenge encourages generalisable solutions capable of working across many datasets and tasks.\n",
    "\n",
    "This notebook demonstrates how to use the `neuros` package to extract DINOv3 features and train simple segmentation models. We first show how one might download and load the raw data; if you are running in an environment without internet access you can skip those cells. For demonstration purposes we generate a synthetic dataset that mimics the modality of this dataset and perform a lightweight comparison of two DINOv3 backbones (ConvNeXt-Tiny and ViT-Large) on a binary segmentation task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08955dd0",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "If you have network access and the necessary permissions, you can download the dataset using the following commands. These lines are commented out by default to prevent accidental downloads in restricted environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad407ac",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Download a sample sequence from the Cell Tracking Challenge. Replace `DIC-C2DH-HeLa` # with another dataset of interest.\n",
    "# !wget -O ctc-HeLa.zip https://huggingface.co/datasets/celltrackingchallenge/DIC-C2DH-HeLa/resolve/main/DIC-C2DH-HeLa.zip\n",
    "# !unzip ctc-HeLa.zip -d ./cell_tracking_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a97d0",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The following code shows how you might load the downloaded files into Python. Adjust the paths as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c5939",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example: load 2D+t images from a CTC dataset using tifffile.\n",
    "# import tifffile\n",
    "# imgs = tifffile.imread('cell_tracking_data/train/images.tif')  # shape (T,H,W)\n",
    "# labels = tifffile.imread('cell_tracking_data/train/labels.tif')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from neuros.plugins.cv.dinov3_backbone import DINOv3Backbone\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset(num_images: int, size: int = 128, mode: str = \"tracking\"):\n",
    "    \"\"\"Generate a synthetic dataset for the specified modality.\"\"\"\n",
    "    images, masks = [], []\n",
    "    rng = np.random.default_rng(123)\n",
    "    for _ in range(num_images):\n",
    "        if mode == \"em\":\n",
    "            # Round neurites on noisy background\n",
    "            img = rng.normal(0.5, 0.15, size=(size, size, 1)).clip(0,1)\n",
    "            mask = np.zeros((size,size), int)\n",
    "            for _ in range(rng.integers(3,7)):\n",
    "                cx,cy = rng.integers(0,size,2)\n",
    "                r = rng.integers(size//20, size//10)\n",
    "                Y, X = np.ogrid[:size,:size]\n",
    "                circle = (X-cx)**2 + (Y-cy)**2 <= r**2\n",
    "                mask[circle] = 1\n",
    "                img[circle] += 0.5\n",
    "            img = img.clip(0,1)\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        elif mode == \"mri\":\n",
    "            # Smooth gradient with circular lesion\n",
    "            x = np.linspace(-1,1,size)\n",
    "            y = np.linspace(-1,1,size)\n",
    "            X,Y = np.meshgrid(x,y)\n",
    "            img = 0.5 + 0.5*(X+Y)/2\n",
    "            mask = ((X**2 + Y**2) < 0.2**2).astype(int)\n",
    "            img[mask==1] = 1.0\n",
    "            img_rgb = np.repeat(img[:,:,None],3,axis=2)\n",
    "        elif mode == \"histology\":\n",
    "            # Textured tissue with darker nucleus\n",
    "            base = rng.uniform(0.8,1.0, size=(size,size,3))\n",
    "            noise = rng.normal(0,0.05, size=(size,size,3))\n",
    "            img_rgb = (base + noise).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            cx,cy = rng.integers(size//4,3*size//4,2)\n",
    "            r = size//6\n",
    "            Y,X = np.ogrid[:size,:size]\n",
    "            nucleus = (X-cx)**2 + (Y-cy)**2 <= r**2\n",
    "            mask[nucleus] = 1\n",
    "            img_rgb[nucleus] -= 0.4\n",
    "            img_rgb = img_rgb.clip(0,1)\n",
    "        elif mode == \"connectomics\":\n",
    "            # Curvilinear neurites\n",
    "            img = rng.normal(0.5,0.15,(size,size,1)).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_strands = rng.integers(2,5)\n",
    "            Y = np.arange(size)\n",
    "            for _ in range(num_strands):\n",
    "                amp = rng.uniform(5,20)\n",
    "                freq = rng.uniform(0.02,0.1)\n",
    "                phase = rng.uniform(0,2*np.pi)\n",
    "                center = rng.uniform(size*0.2,size*0.8)\n",
    "                x_vals = center + amp*np.sin(freq*Y + phase)\n",
    "                for y,x_center in enumerate(x_vals.astype(int)):\n",
    "                    x_center = np.clip(x_center, 0, size-1)\n",
    "                    width = rng.integers(size//50, size//30)\n",
    "                    xs = max(x_center - width,0)\n",
    "                    xe = min(x_center + width, size-1)\n",
    "                    mask[y, xs:xe] = 1\n",
    "                    img[y,xs:xe,0] = 1.0\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        elif mode == \"atlas\":\n",
    "            # Coarse anatomical regions with colour shifts\n",
    "            img_rgb = rng.uniform(0.4,0.8,(size,size,3))\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_regions = rng.integers(3,6)\n",
    "            centers = rng.integers(size//4,3*size//4,(num_regions,2))\n",
    "            radii = rng.integers(size//10,size//5,num_regions)\n",
    "            labels = rng.permutation(num_regions)\n",
    "            Y,X = np.ogrid[:size,:size]\n",
    "            for idx,(cx,cy) in enumerate(centers):\n",
    "                region = (X-cx)**2 + (Y-cy)**2 <= radii[idx]**2\n",
    "                mask[region] = labels[idx] + 1\n",
    "                color_shift = rng.uniform(-0.1,0.1,3)\n",
    "                img_rgb[region] = np.clip(img_rgb[region] + color_shift,0,1)\n",
    "        elif mode == \"calcium\":\n",
    "            # Bright circular ROIs on noisy background\n",
    "            img = rng.normal(0.4,0.1,(size,size,1)).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_cells = rng.integers(3,8)\n",
    "            for _ in range(num_cells):\n",
    "                cx,cy = rng.integers(0,size,2)\n",
    "                r = rng.integers(size//30,size//15)\n",
    "                Y,X = np.ogrid[:size,:size]\n",
    "                cell = (X-cx)**2 + (Y-cy)**2 <= r**2\n",
    "                mask[cell] = 1\n",
    "                img[cell] += 0.6\n",
    "            img = img.clip(0,1)\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        elif mode == \"tracking\":\n",
    "            # Overlapping ellipses representing cells\n",
    "            img = rng.normal(0.5,0.1,(size,size,1)).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_cells = rng.integers(5,10)\n",
    "            for label in range(1,num_cells+1):\n",
    "                cx,cy = rng.integers(0,size,2)\n",
    "                rx = rng.integers(size//40,size//20)\n",
    "                ry = rng.integers(size//40,size//20)\n",
    "                angle = rng.uniform(0,np.pi)\n",
    "                Yg,Xg = np.ogrid[:size,:size]\n",
    "                x_rot = (Xg-cx)*np.cos(angle)+(Yg-cy)*np.sin(angle)\n",
    "                y_rot = -(Xg-cx)*np.sin(angle)+(Yg-cy)*np.cos(angle)\n",
    "                ellipse = (x_rot/rx)**2 + (y_rot/ry)**2 <= 1\n",
    "                mask[ellipse] = 1\n",
    "                img[ellipse] += 0.5\n",
    "            img = img.clip(0,1)\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "        images.append((img_rgb*255).astype(np.uint8))\n",
    "        masks.append((mask>0).astype(int))\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def flatten_dataset(images, masks, backbone):\n",
    "    \"\"\"Flatten patch features and binary labels for a dataset.\"\"\"\n",
    "    all_feats, all_labels = [], []\n",
    "    for img, mask in zip(images, masks):\n",
    "        pf = backbone.embed([img])[0]\n",
    "        gs = backbone.grid_size\n",
    "        ps = backbone.patch_size\n",
    "        mask_crop = mask[:gs*ps, :gs*ps]\n",
    "        patch_mask = mask_crop.reshape(gs, ps, gs, ps)\n",
    "        labels = (patch_mask.sum(axis=(1,3)) > (ps*ps/2)).astype(int)\n",
    "        all_feats.append(pf)\n",
    "        all_labels.append(labels.flatten())\n",
    "    return np.concatenate(all_feats), np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "def evaluate_backbones(mode: str):\n",
    "    \"\"\"Train and evaluate ConvNeXt-Tiny and ViT-Large on the given synthetic modality.\"\"\"\n",
    "    results = {}\n",
    "    for back_name, model_id in [\n",
    "        ('CNX-T', 'facebook/dinov3-convnext-tiny-pretrain-lvd1689m'),\n",
    "        ('ViT-L', 'facebook/dinov3-vit-large-pretrain-lvd1689m')\n",
    "    ]:\n",
    "        backbone = DINOv3Backbone(model_id=model_id)\n",
    "        # generate a small training and test set\n",
    "        train_images, train_masks = generate_synthetic_dataset(8, mode=mode)\n",
    "        test_images, test_masks = generate_synthetic_dataset(4, mode=mode)\n",
    "        X_train, y_train = flatten_dataset(train_images, train_masks, backbone)\n",
    "        X_test, y_test = flatten_dataset(test_images, test_masks, backbone)\n",
    "        # handle single class case\n",
    "        if len(np.unique(y_train)) < 2:\n",
    "            majority = y_train[0]\n",
    "            preds = np.full_like(y_test, majority)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            clf = LogisticRegression(max_iter=300)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            f1 = f1_score(y_test, preds)\n",
    "        results[back_name] = (acc, f1)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate DINOv3 backbones on a synthetic representation of this dataset\n",
    "results = evaluate_backbones(\"tracking\")\n",
    "for model, (acc, f1) in results.items():\n",
    "    print(f\"{model} accuracy: {acc:.3f}, F1 score: {f1:.3f}\")\n",
    "\n",
    "models = list(results.keys())\n",
    "accs = [results[m][0] for m in models]\n",
    "f1s = [results[m][1] for m in models]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(models, accs)\n",
    "plt.title(\"Segmentation accuracy on synthetic tracking dataset\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(models, f1s)\n",
    "plt.title(\"F1 score on synthetic tracking dataset\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
