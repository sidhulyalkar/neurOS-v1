{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6ecfc8",
   "metadata": {},
   "source": [
    "# Extended DINOv3 Experiments\n",
    "\n",
    "This notebook accompanies the extended neurOS evaluation of **DINOv3** backbones\n",
    "on synthetic datasets inspired by a range of neuroscience modalities.  It\n",
    "demonstrates how to generate synthetic images, extract placeholder\n",
    "features via the neurOS DINOv3 plugin, train simple segmentation\n",
    "classifiers and evaluate cross‑modality performance.  We also assess\n",
    "translation‑based registration via patch correlations.  All code\n",
    "illustrated here is self‑contained and does not depend on external\n",
    "internet resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c29d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from neuros.plugins.cv.dinov3_backbone import DINOv3Backbone\n",
    "from neuros.plugins.cv.feature_matching import patch_correlation, estimate_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mapping of modality names to generation functions defined in the script\n",
    "from __main__ import generate_dataset\n",
    "\n",
    "modalities = [\"em\", \"mri\", \"histology\", \"connectomics\", \"atlas\", \"calcium\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b1b0a",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset generation\n",
    "\n",
    "We synthesise images and masks for each of six modalities.  The\n",
    "functions `generate_dataset` and associated helpers are implemented in\n",
    "the companion script.  Below we generate a few samples per modality and\n",
    "display them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(len(modalities), 4, figsize=(8, 2 * len(modalities)))\n",
    "for i, modality in enumerate(modalities):\n",
    "    imgs, masks = generate_dataset(modality, n_samples=4)\n",
    "    for j, (img, msk) in enumerate(zip(imgs, masks)):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(img)\n",
    "        ax.imshow(msk, cmap=\"Reds\", alpha=0.3)\n",
    "        ax.set_title(f\"{modality} #{j}\")\n",
    "        ax.axis(\"off\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac80ac",
   "metadata": {},
   "source": [
    "\n",
    "## Segmentation experiments\n",
    "\n",
    "We now evaluate segmentation on each modality.  For each backbone\n",
    "(`cnx-tiny` and `vit-large`), we train a logistic regression on\n",
    "patch embeddings to classify patches as foreground (mask=1) or\n",
    "background (mask=0).  We compute accuracy and F1 score on a held‑out\n",
    "test set.  Finally, we explore cross‑modality transfer by training on\n",
    "one modality and testing on all others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_segmentation(modality, backbone_name):\n",
    "    # generate train and test sets\n",
    "    train_imgs, train_masks = generate_dataset(modality, n_samples=10)\n",
    "    test_imgs, test_masks = generate_dataset(modality, n_samples=5)\n",
    "    # flatten features and labels\n",
    "    X_train, y_train = flatten_for_segmentation(train_imgs, train_masks, backbone_name)\n",
    "    X_test, y_test = flatten_for_segmentation(test_imgs, test_masks, backbone_name)\n",
    "    # if no positive samples, return majority baseline\n",
    "    if np.sum(y_train) == 0 or np.sum(y_test) == 0:\n",
    "        y_pred = np.zeros_like(y_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = 0.0\n",
    "        return acc, f1\n",
    "    # train logistic regression\n",
    "    clf = LogisticRegression(max_iter=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return acc, f1\n",
    "\n",
    "# compute segmentation results for each modality and backbone\n",
    "results = {}\n",
    "for modality in modalities:\n",
    "    results[modality] = {}\n",
    "    for backbone_name in [\"cnx-tiny\", \"vit-large\"]:\n",
    "        acc, f1 = evaluate_segmentation(modality, backbone_name)\n",
    "        results[modality][backbone_name] = (acc, f1)\n",
    "        print(f\"{modality}-{backbone_name}: accuracy={acc:.3f}, F1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68378dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    (modality, backbone): results[modality][backbone]\n",
    "    for modality in modalities\n",
    "    for backbone in [\"cnx-tiny\", \"vit-large\"]\n",
    "}, index=[\"Accuracy\", \"F1\"]).T\n",
    "\n",
    "import caas_jupyter_tools\n",
    "caas_jupyter_tools.display_dataframe_to_user(name=\"Segmentation results\", dataframe=df_results)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33062d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross‑modality generalisation\n",
    "\n",
    "def evaluate_cross_modal(train_mod, test_mod, backbone_name):\n",
    "    train_imgs, train_masks = generate_dataset(train_mod, n_samples=10)\n",
    "    test_imgs, test_masks = generate_dataset(test_mod, n_samples=5)\n",
    "    X_train, y_train = flatten_for_segmentation(train_imgs, train_masks, backbone_name)\n",
    "    X_test, y_test = flatten_for_segmentation(test_imgs, test_masks, backbone_name)\n",
    "    # train majority if no positives\n",
    "    if np.sum(y_train) == 0 or np.sum(y_test) == 0:\n",
    "        y_pred = np.zeros_like(y_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = 0.0\n",
    "        return acc, f1\n",
    "    clf = LogisticRegression(max_iter=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return acc, f1\n",
    "\n",
    "cross_results = {}\n",
    "for backbone_name in [\"cnx-tiny\", \"vit-large\"]:\n",
    "    cross_results[backbone_name] = {}\n",
    "    for train_mod in modalities:\n",
    "        cross_results[backbone_name][train_mod] = {}\n",
    "        for test_mod in modalities:\n",
    "            acc, f1 = evaluate_cross_modal(train_mod, test_mod, backbone_name)\n",
    "            cross_results[backbone_name][train_mod][test_mod] = (acc, f1)\n",
    "\n",
    "# display cross results as dataframes for each backbone\n",
    "for backbone_name in [\"cnx-tiny\", \"vit-large\"]:\n",
    "    data_acc = pd.DataFrame(\n",
    "        {train_mod: {test_mod: cross_results[backbone_name][train_mod][test_mod][0]\n",
    "                     for test_mod in modalities}\n",
    "         for train_mod in modalities}\n",
    "    )\n",
    "    data_f1 = pd.DataFrame(\n",
    "        {train_mod: {test_mod: cross_results[backbone_name][train_mod][test_mod][1]\n",
    "                     for test_mod in modalities}\n",
    "         for train_mod in modalities}\n",
    "    )\n",
    "    print(f\"\n",
    "Cross‑modality accuracy matrix for {backbone_name}:\")\n",
    "    display(data_acc)\n",
    "    print(f\"\n",
    "Cross‑modality F1 matrix for {backbone_name}:\")\n",
    "    display(data_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8bbd29",
   "metadata": {},
   "source": [
    "\n",
    "## Registration experiments\n",
    "\n",
    "To approximate slice‑to‑slice alignment we shift images by multiples of\n",
    "the 16×16 patch size and attempt to recover the translation from patch\n",
    "correlations.  For each modality and backbone we compute the mean\n",
    "absolute error (in patch units) across three shifts: (1, 1), (0, 2)\n",
    "and (−2, −1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7fb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_registration(modality, backbone_name):\n",
    "    return estimate_shift_error(modality, backbone_name)\n",
    "\n",
    "reg_results = {}\n",
    "for modality in modalities:\n",
    "    reg_results[modality] = {}\n",
    "    for backbone_name in [\"cnx-tiny\", \"vit-large\"]:\n",
    "        err = evaluate_registration(modality, backbone_name)\n",
    "        reg_results[modality][backbone_name] = err\n",
    "        print(f\"{modality}-{backbone_name}: mean shift error = {err:.3f} patches\")\n",
    "\n",
    "df_reg = pd.DataFrame(reg_results).T\n",
    "caas_jupyter_tools.display_dataframe_to_user(name=\"Registration errors\", dataframe=df_reg)\n",
    "df_reg\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
