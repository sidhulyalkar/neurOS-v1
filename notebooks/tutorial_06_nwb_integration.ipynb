{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: NWB Integration & Real-World Data\n",
    "\n",
    "**Level**: Intermediate  \n",
    "**Time**: 35-45 minutes  \n",
    "**Prerequisites**: Tutorial 1, Tutorial 2\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, you'll learn how to:\n",
    "\n",
    "1. **Work with NWB Format** - Neurodata Without Borders standard\n",
    "2. **Load Real Datasets** - Import existing NWB files\n",
    "3. **Export to NWB** - Save your neurOS data\n",
    "4. **BIDS Compliance** - Brain Imaging Data Structure conventions\n",
    "5. **Metadata Management** - Organize experimental data\n",
    "6. **Share & Publish** - Prepare data for repositories\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **NWB (Neurodata Without Borders)**: Community standard for neurophysiology\n",
    "- **BIDS**: Standardized folder structure\n",
    "- **Metadata**: Experimental details, subject info, equipment\n",
    "- **Data Provenance**: Tracking processing history\n",
    "- **Interoperability**: Working with other tools\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Understanding the NWB Format\n",
    "\n",
    "NWB is built on HDF5 and provides a standardized way to store neurophysiology data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# neurOS imports\n",
    "from neuros.drivers import MockDriver\n",
    "from neuros.models import SimpleClassifier\n",
    "from neuros.pipeline import Pipeline\n",
    "\n",
    "# NWB support (optional dependency)\n",
    "try:\n",
    "    from pynwb import NWBFile, NWBHDF5IO\n",
    "    from pynwb.ecephys import ElectricalSeries, LFP\n",
    "    from pynwb.behavior import BehavioralTimeSeries\n",
    "    from pynwb.device import Device\n",
    "    from pynwb.file import Subject\n",
    "    PYNWB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYNWB_AVAILABLE = False\n",
    "    print(\"âš  pynwb not installed. Install with: pip install pynwb\")\n",
    "    print(\"  This tutorial will show structure without actual NWB I/O.\")\n",
    "\n",
    "print(f\"NWB Support: {'âœ“ Available' if PYNWB_AVAILABLE else 'âœ— Not installed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NWB File Structure\n",
    "\n",
    "An NWB file contains:\n",
    "\n",
    "```\n",
    "NWB File\n",
    "â”œâ”€â”€ General Metadata\n",
    "â”‚   â”œâ”€â”€ Session info (experimenter, lab, institution)\n",
    "â”‚   â”œâ”€â”€ Subject info (species, age, sex)\n",
    "â”‚   â””â”€â”€ Devices (hardware used)\n",
    "â”œâ”€â”€ Acquisition\n",
    "â”‚   â”œâ”€â”€ Raw data (ElectricalSeries)\n",
    "â”‚   â””â”€â”€ Behavioral data\n",
    "â”œâ”€â”€ Processing\n",
    "â”‚   â”œâ”€â”€ Filtered data\n",
    "â”‚   â”œâ”€â”€ LFP (Local Field Potential)\n",
    "â”‚   â””â”€â”€ Spike trains\n",
    "â””â”€â”€ Analysis\n",
    "    â”œâ”€â”€ Processed results\n",
    "    â””â”€â”€ Model predictions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Creating an NWB File from Scratch\n",
    "\n",
    "Let's create a complete NWB file with mock EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYNWB_AVAILABLE:\n",
    "    def create_example_nwb_file(filepath: str) -> None:\n",
    "        \"\"\"\n",
    "        Create a complete example NWB file.\n",
    "        \"\"\"\n",
    "        # Create NWB file with metadata\n",
    "        nwbfile = NWBFile(\n",
    "            session_description='Motor imagery BCI session with 4-class classification',\n",
    "            identifier='neuros_tutorial_session_001',\n",
    "            session_start_time=datetime.now(),\n",
    "            experimenter='Dr. Neural Researcher',\n",
    "            lab='BCI Lab',\n",
    "            institution='University of NeuroScience',\n",
    "            experiment_description='Motor imagery classification using EEG',\n",
    "            session_id='session_001',\n",
    "            keywords=['BCI', 'motor imagery', 'EEG', 'classification']\n",
    "        )\n",
    "        \n",
    "        # Add subject information\n",
    "        nwbfile.subject = Subject(\n",
    "            subject_id='P001',\n",
    "            age='25',\n",
    "            sex='M',\n",
    "            species='Homo sapiens',\n",
    "            description='Healthy volunteer'\n",
    "        )\n",
    "        \n",
    "        # Add device information\n",
    "        device = nwbfile.create_device(\n",
    "            name='ActiChamp',\n",
    "            description='BrainProducts ActiChamp 64-channel EEG',\n",
    "            manufacturer='Brain Products GmbH'\n",
    "        )\n",
    "        \n",
    "        # Create electrode group\n",
    "        electrode_group = nwbfile.create_electrode_group(\n",
    "            name='EEG_electrodes',\n",
    "            description='64-channel 10-20 system',\n",
    "            location='scalp',\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Add electrode locations\n",
    "        n_channels = 64\n",
    "        for i in range(n_channels):\n",
    "            nwbfile.add_electrode(\n",
    "                id=i,\n",
    "                x=0.0,  # In practice, use real coordinates\n",
    "                y=0.0,\n",
    "                z=0.0,\n",
    "                imp=float('nan'),  # Impedance\n",
    "                location=f'Channel_{i+1}',\n",
    "                filtering='none',\n",
    "                group=electrode_group\n",
    "            )\n",
    "        \n",
    "        # Create electrode table region\n",
    "        electrode_table_region = nwbfile.create_electrode_table_region(\n",
    "            region=list(range(n_channels)),\n",
    "            description='all electrodes'\n",
    "        )\n",
    "        \n",
    "        # Generate mock EEG data\n",
    "        sampling_rate = 250.0  # Hz\n",
    "        duration = 10.0  # seconds\n",
    "        n_samples = int(sampling_rate * duration)\n",
    "        \n",
    "        # Simulate 4 trials (one per class)\n",
    "        data = np.random.randn(n_samples, n_channels) * 50  # microvolts\n",
    "        \n",
    "        # Add raw data as ElectricalSeries\n",
    "        raw_eeg = ElectricalSeries(\n",
    "            name='raw_eeg',\n",
    "            data=data,\n",
    "            electrodes=electrode_table_region,\n",
    "            starting_time=0.0,\n",
    "            rate=sampling_rate,\n",
    "            description='Raw EEG data',\n",
    "            comments='Acquired during motor imagery task',\n",
    "            conversion=1e-6  # Convert to Volts\n",
    "        )\n",
    "        \n",
    "        nwbfile.add_acquisition(raw_eeg)\n",
    "        \n",
    "        # Add trial information\n",
    "        nwbfile.add_trial_column('trial_type', 'motor imagery class')\n",
    "        nwbfile.add_trial_column('accuracy', 'classification accuracy')\n",
    "        \n",
    "        trial_types = ['left_hand', 'right_hand', 'feet', 'tongue']\n",
    "        trial_duration = duration / 4\n",
    "        \n",
    "        for i, trial_type in enumerate(trial_types):\n",
    "            nwbfile.add_trial(\n",
    "                start_time=i * trial_duration,\n",
    "                stop_time=(i + 1) * trial_duration,\n",
    "                trial_type=trial_type,\n",
    "                accuracy=0.75 + np.random.rand() * 0.2  # Mock accuracy\n",
    "            )\n",
    "        \n",
    "        # Save to file\n",
    "        with NWBHDF5IO(filepath, 'w') as io:\n",
    "            io.write(nwbfile)\n",
    "        \n",
    "        print(f\"âœ“ NWB file created: {filepath}\")\n",
    "        print(f\"  Channels: {n_channels}\")\n",
    "        print(f\"  Samples: {n_samples}\")\n",
    "        print(f\"  Duration: {duration}s\")\n",
    "        print(f\"  Trials: {len(trial_types)}\")\n",
    "    \n",
    "    # Create example file\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    nwb_filepath = os.path.join(temp_dir, 'example_session.nwb')\n",
    "    create_example_nwb_file(nwb_filepath)\n",
    "    \n",
    "else:\n",
    "    print(\"\\nExample NWB file structure (conceptual):\")\n",
    "    print(\"\"\"   \n",
    "    NWBFile(\n",
    "        session_description='Motor imagery BCI session',\n",
    "        experimenter='Dr. Researcher',\n",
    "        devices=['ActiChamp 64-ch EEG'],\n",
    "        electrodes=[Ch1, Ch2, ..., Ch64],\n",
    "        acquisition={'raw_eeg': ElectricalSeries},\n",
    "        trials=[Trial1, Trial2, Trial3, Trial4]\n",
    "    )\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Reading and Exploring NWB Files\n",
    "\n",
    "Load and inspect an existing NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYNWB_AVAILABLE:\n",
    "    def explore_nwb_file(filepath: str) -> None:\n",
    "        \"\"\"\n",
    "        Explore the contents of an NWB file.\n",
    "        \"\"\"\n",
    "        with NWBHDF5IO(filepath, 'r') as io:\n",
    "            nwbfile = io.read()\n",
    "            \n",
    "            print(\"NWB File Contents:\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Session info\n",
    "            print(\"\\nðŸ“‹ Session Information:\")\n",
    "            print(f\"  Description: {nwbfile.session_description}\")\n",
    "            print(f\"  Start time: {nwbfile.session_start_time}\")\n",
    "            print(f\"  Experimenter: {nwbfile.experimenter}\")\n",
    "            print(f\"  Lab: {nwbfile.lab}\")\n",
    "            print(f\"  Institution: {nwbfile.institution}\")\n",
    "            \n",
    "            # Subject info\n",
    "            if nwbfile.subject:\n",
    "                print(\"\\nðŸ‘¤ Subject Information:\")\n",
    "                print(f\"  ID: {nwbfile.subject.subject_id}\")\n",
    "                print(f\"  Age: {nwbfile.subject.age}\")\n",
    "                print(f\"  Sex: {nwbfile.subject.sex}\")\n",
    "                print(f\"  Species: {nwbfile.subject.species}\")\n",
    "            \n",
    "            # Devices\n",
    "            print(\"\\nðŸ”§ Devices:\")\n",
    "            for device_name, device in nwbfile.devices.items():\n",
    "                print(f\"  {device_name}: {device.description}\")\n",
    "            \n",
    "            # Electrodes\n",
    "            print(f\"\\nðŸ“¡ Electrodes: {len(nwbfile.electrodes)} channels\")\n",
    "            \n",
    "            # Acquisition\n",
    "            print(\"\\nðŸ“Š Acquisition Data:\")\n",
    "            for name, data in nwbfile.acquisition.items():\n",
    "                if hasattr(data, 'data'):\n",
    "                    shape = data.data.shape\n",
    "                    rate = data.rate if hasattr(data, 'rate') else 'N/A'\n",
    "                    print(f\"  {name}: shape={shape}, rate={rate} Hz\")\n",
    "            \n",
    "            # Trials\n",
    "            if nwbfile.trials:\n",
    "                print(f\"\\nðŸŽ¯ Trials: {len(nwbfile.trials)} trials\")\n",
    "                print(f\"  Columns: {list(nwbfile.trials.colnames)}\")\n",
    "    \n",
    "    # Explore the file we just created\n",
    "    explore_nwb_file(nwb_filepath)\n",
    "    \n",
    "else:\n",
    "    print(\"Install pynwb to explore NWB files: pip install pynwb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYNWB_AVAILABLE:\n",
    "    with NWBHDF5IO(nwb_filepath, 'r') as io:\n",
    "        nwbfile = io.read()\n",
    "        \n",
    "        # Extract EEG data\n",
    "        raw_eeg = nwbfile.acquisition['raw_eeg']\n",
    "        data = raw_eeg.data[:]\n",
    "        sampling_rate = raw_eeg.rate\n",
    "        \n",
    "        # Time axis\n",
    "        time = np.arange(data.shape[0]) / sampling_rate\n",
    "        \n",
    "        # Extract trial information\n",
    "        trials_df = nwbfile.trials.to_dataframe()\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Plot first 4 channels\n",
    "    for i in range(4):\n",
    "        ax1.plot(time, data[:, i] + i*100, linewidth=0.5, label=f'Ch {i+1}')\n",
    "    \n",
    "    # Mark trial boundaries\n",
    "    colors = ['red', 'green', 'blue', 'orange']\n",
    "    for idx, trial in trials_df.iterrows():\n",
    "        ax1.axvline(trial['start_time'], color=colors[idx], linestyle='--', \n",
    "                    alpha=0.5, linewidth=2)\n",
    "        ax1.text(trial['start_time'], 350, trial['trial_type'], \n",
    "                rotation=90, fontsize=9)\n",
    "    \n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Channels (offset for visibility)')\n",
    "    ax1.set_title('Raw EEG Data with Trial Markers')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot trial accuracies\n",
    "    trial_types = trials_df['trial_type'].values\n",
    "    accuracies = trials_df['accuracy'].values\n",
    "    \n",
    "    bars = ax2.bar(range(len(trial_types)), accuracies, \n",
    "                   color=colors[:len(trial_types)])\n",
    "    ax2.set_xticks(range(len(trial_types)))\n",
    "    ax2.set_xticklabels(trial_types)\n",
    "    ax2.set_ylabel('Classification Accuracy')\n",
    "    ax2.set_title('Per-Trial Classification Accuracy')\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1%}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nData Statistics:\")\n",
    "    print(f\"  Shape: {data.shape}\")\n",
    "    print(f\"  Sampling rate: {sampling_rate} Hz\")\n",
    "    print(f\"  Duration: {len(time)/sampling_rate:.1f}s\")\n",
    "    print(f\"  Mean accuracy: {accuracies.mean():.1%}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Visualization requires pynwb installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Integrating neurOS with NWB\n",
    "\n",
    "Use NWB data directly in neurOS pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NWBDataLoader:\n",
    "    \"\"\"\n",
    "    Load NWB data for use in neurOS pipelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nwb_filepath: str):\n",
    "        self.filepath = nwb_filepath\n",
    "        self.nwbfile = None\n",
    "    \n",
    "    def load_eeg_data(self, series_name: str = 'raw_eeg') -> dict:\n",
    "        \"\"\"\n",
    "        Load EEG data from NWB file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Dictionary with 'data', 'sampling_rate', 'time', 'metadata'\n",
    "        \"\"\"\n",
    "        if not PYNWB_AVAILABLE:\n",
    "            raise ImportError(\"pynwb is required\")\n",
    "        \n",
    "        with NWBHDF5IO(self.filepath, 'r') as io:\n",
    "            nwbfile = io.read()\n",
    "            \n",
    "            # Extract EEG series\n",
    "            eeg_series = nwbfile.acquisition[series_name]\n",
    "            data = eeg_series.data[:]\n",
    "            sampling_rate = eeg_series.rate\n",
    "            \n",
    "            # Create time axis\n",
    "            time = np.arange(data.shape[0]) / sampling_rate\n",
    "            \n",
    "            # Extract metadata\n",
    "            metadata = {\n",
    "                'session_description': nwbfile.session_description,\n",
    "                'experimenter': nwbfile.experimenter,\n",
    "                'session_start_time': str(nwbfile.session_start_time),\n",
    "                'n_channels': data.shape[1],\n",
    "                'n_samples': data.shape[0],\n",
    "                'duration_s': time[-1]\n",
    "            }\n",
    "            \n",
    "            # Extract trials if available\n",
    "            trials = None\n",
    "            if nwbfile.trials:\n",
    "                trials = nwbfile.trials.to_dataframe()\n",
    "        \n",
    "        return {\n",
    "            'data': data,\n",
    "            'sampling_rate': sampling_rate,\n",
    "            'time': time,\n",
    "            'metadata': metadata,\n",
    "            'trials': trials\n",
    "        }\n",
    "    \n",
    "    def prepare_for_pipeline(self, window_size: int = 250) -> tuple:\n",
    "        \"\"\"\n",
    "        Prepare NWB data for neurOS pipeline.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (X, y, metadata) ready for training/prediction\n",
    "        \"\"\"\n",
    "        data_dict = self.load_eeg_data()\n",
    "        data = data_dict['data']\n",
    "        trials = data_dict['trials']\n",
    "        sampling_rate = data_dict['sampling_rate']\n",
    "        \n",
    "        # Extract windows based on trials\n",
    "        X_windows = []\n",
    "        y_labels = []\n",
    "        \n",
    "        if trials is not None:\n",
    "            for idx, trial in trials.iterrows():\n",
    "                start_idx = int(trial['start_time'] * sampling_rate)\n",
    "                end_idx = int(trial['stop_time'] * sampling_rate)\n",
    "                \n",
    "                # Extract window\n",
    "                window = data[start_idx:end_idx, :]\n",
    "                \n",
    "                # Flatten for simple classifier\n",
    "                features = window.mean(axis=0)  # Simple: mean across time\n",
    "                \n",
    "                X_windows.append(features)\n",
    "                y_labels.append(idx)  # Use trial index as label\n",
    "        \n",
    "        X = np.array(X_windows)\n",
    "        y = np.array(y_labels)\n",
    "        \n",
    "        return X, y, data_dict['metadata']\n",
    "\n",
    "if PYNWB_AVAILABLE:\n",
    "    # Load NWB data\n",
    "    loader = NWBDataLoader(nwb_filepath)\n",
    "    X, y, metadata = loader.prepare_for_pipeline()\n",
    "    \n",
    "    print(\"Prepared for neurOS Pipeline:\")\n",
    "    print(f\"  Feature matrix shape: {X.shape}\")\n",
    "    print(f\"  Labels shape: {y.shape}\")\n",
    "    print(f\"  Unique classes: {np.unique(y)}\")\n",
    "    print(f\"\\nMetadata: {metadata}\")\n",
    "    \n",
    "else:\n",
    "    # Use mock data if NWB not available\n",
    "    X = np.random.randn(4, 64)\n",
    "    y = np.array([0, 1, 2, 3])\n",
    "    print(\"Using mock data (pynwb not installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Pipeline on NWB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "driver = MockDriver(n_channels=X.shape[1], sampling_rate=250)\n",
    "model = SimpleClassifier(model_type='logistic')\n",
    "\n",
    "pipeline = Pipeline(driver=driver, model=model)\n",
    "\n",
    "# Train on NWB data (with cross-validation for small dataset)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if len(X) >= 3:  # Need at least 3 samples\n",
    "    scores = cross_val_score(model, X, y, cv=min(3, len(X)))\n",
    "    print(f\"\\nCross-validation accuracy: {scores.mean():.2%} (+/- {scores.std():.2%})\")\n",
    "else:\n",
    "    model.train(X, y)\n",
    "    print(\"\\nModel trained on full dataset (too small for CV)\")\n",
    "\n",
    "print(\"\\nâœ“ neurOS pipeline successfully trained on NWB data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Exporting neurOS Results to NWB\n",
    "\n",
    "Save your processing pipeline results in NWB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYNWB_AVAILABLE:\n",
    "    def export_results_to_nwb(\n",
    "        original_nwb_path: str,\n",
    "        output_path: str,\n",
    "        predictions: np.ndarray,\n",
    "        model_name: str = 'SimpleClassifier'\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Export neurOS processing results back to NWB format.\n",
    "        \"\"\"\n",
    "        # Load original file\n",
    "        with NWBHDF5IO(original_nwb_path, 'r') as io:\n",
    "            nwbfile_in = io.read()\n",
    "            \n",
    "            # Create new file with original metadata\n",
    "            nwbfile_out = NWBFile(\n",
    "                session_description=nwbfile_in.session_description + ' [Processed]',\n",
    "                identifier=nwbfile_in.identifier + '_processed',\n",
    "                session_start_time=nwbfile_in.session_start_time,\n",
    "                experimenter=nwbfile_in.experimenter,\n",
    "                lab=nwbfile_in.lab,\n",
    "                institution=nwbfile_in.institution\n",
    "            )\n",
    "            \n",
    "            # Copy subject info\n",
    "            if nwbfile_in.subject:\n",
    "                nwbfile_out.subject = Subject(\n",
    "                    subject_id=nwbfile_in.subject.subject_id,\n",
    "                    age=nwbfile_in.subject.age,\n",
    "                    sex=nwbfile_in.subject.sex,\n",
    "                    species=nwbfile_in.subject.species\n",
    "                )\n",
    "            \n",
    "            # Create processing module\n",
    "            processing_module = nwbfile_out.create_processing_module(\n",
    "                name='neuros_analysis',\n",
    "                description=f'neurOS pipeline analysis with {model_name}'\n",
    "            )\n",
    "            \n",
    "            # Add predictions as BehavioralTimeSeries\n",
    "            pred_series = BehavioralTimeSeries(\n",
    "                name='model_predictions',\n",
    "                description=f'Predictions from {model_name}',\n",
    "                data=predictions.reshape(-1, 1),\n",
    "                timestamps=np.arange(len(predictions)),\n",
    "                unit='class_label'\n",
    "            )\n",
    "            \n",
    "            processing_module.add(pred_series)\n",
    "        \n",
    "        # Write output file\n",
    "        with NWBHDF5IO(output_path, 'w') as io:\n",
    "            io.write(nwbfile_out)\n",
    "        \n",
    "        print(f\"âœ“ Results exported to: {output_path}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    # Export\n",
    "    output_nwb_path = os.path.join(temp_dir, 'processed_results.nwb')\n",
    "    export_results_to_nwb(nwb_filepath, output_nwb_path, predictions)\n",
    "    \n",
    "else:\n",
    "    print(\"NWB export requires pynwb installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: BIDS-Compatible Organization\n",
    "\n",
    "Organize your data following BIDS conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIDS Directory Structure\n",
    "\n",
    "```\n",
    "my_bci_study/\n",
    "â”œâ”€â”€ dataset_description.json\n",
    "â”œâ”€â”€ participants.tsv\n",
    "â”œâ”€â”€ README\n",
    "â”œâ”€â”€ sub-01/\n",
    "â”‚   â””â”€â”€ ses-001/\n",
    "â”‚       â””â”€â”€ eeg/\n",
    "â”‚           â”œâ”€â”€ sub-01_ses-001_task-motorimagery_eeg.nwb\n",
    "â”‚           â”œâ”€â”€ sub-01_ses-001_task-motorimagery_events.tsv\n",
    "â”‚           â””â”€â”€ sub-01_ses-001_task-motorimagery_channels.tsv\n",
    "â”œâ”€â”€ sub-02/\n",
    "â”‚   â””â”€â”€ ses-001/\n",
    "â”‚       â””â”€â”€ eeg/\n",
    "â”‚           â””â”€â”€ ...\n",
    "â””â”€â”€ derivatives/\n",
    "    â””â”€â”€ neuros/\n",
    "        â”œâ”€â”€ sub-01/\n",
    "        â”‚   â””â”€â”€ ses-001/\n",
    "        â”‚       â””â”€â”€ sub-01_ses-001_predictions.nwb\n",
    "        â””â”€â”€ sub-02/\n",
    "            â””â”€â”€ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_bids_structure(base_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a BIDS-compliant directory structure.\n",
    "    \"\"\"\n",
    "    # Create directories\n",
    "    os.makedirs(os.path.join(base_dir, 'sub-01', 'ses-001', 'eeg'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_dir, 'derivatives', 'neuros'), exist_ok=True)\n",
    "    \n",
    "    # Create dataset_description.json\n",
    "    dataset_desc = {\n",
    "        \"Name\": \"Motor Imagery BCI Study\",\n",
    "        \"BIDSVersion\": \"1.6.0\",\n",
    "        \"DatasetType\": \"raw\",\n",
    "        \"Authors\": [\"Dr. Neural Researcher\"],\n",
    "        \"License\": \"CC0\",\n",
    "        \"ReferencesAndLinks\": [\n",
    "            \"https://github.com/your-user/neuros2\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(base_dir, 'dataset_description.json'), 'w') as f:\n",
    "        json.dump(dataset_desc, f, indent=2)\n",
    "    \n",
    "    # Create participants.tsv\n",
    "    participants_data = (\n",
    "        \"participant_id\\tage\\tsex\\tgroup\\n\"\n",
    "        \"sub-01\\t25\\tM\\tcontrol\\n\"\n",
    "        \"sub-02\\t28\\tF\\tcontrol\\n\"\n",
    "    )\n",
    "    \n",
    "    with open(os.path.join(base_dir, 'participants.tsv'), 'w') as f:\n",
    "        f.write(participants_data)\n",
    "    \n",
    "    # Create README\n",
    "    readme = \"\"\"\n",
    "# Motor Imagery BCI Study\n",
    "\n",
    "This dataset contains EEG recordings during motor imagery tasks.\n",
    "\n",
    "## Task Description\n",
    "\n",
    "Participants performed motor imagery of:\n",
    "- Left hand movement\n",
    "- Right hand movement\n",
    "- Feet movement\n",
    "- Tongue movement\n",
    "\n",
    "## Data Acquisition\n",
    "\n",
    "- Device: BrainProducts ActiChamp\n",
    "- Channels: 64 (10-20 system)\n",
    "- Sampling rate: 250 Hz\n",
    "\n",
    "## Analysis\n",
    "\n",
    "Data were processed using neurOS (https://github.com/your-user/neuros2).\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(os.path.join(base_dir, 'README'), 'w') as f:\n",
    "        f.write(readme.strip())\n",
    "    \n",
    "    print(f\"âœ“ BIDS structure created at: {base_dir}\")\n",
    "    print(\"\\nStructure:\")\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        level = root.replace(base_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "\n",
    "# Create BIDS structure\n",
    "bids_dir = os.path.join(temp_dir, 'bids_dataset')\n",
    "create_bids_structure(bids_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "âœ… **NWB Format** - Structure and benefits  \n",
    "âœ… **Create NWB Files** - From scratch with metadata  \n",
    "âœ… **Read NWB Files** - Load and explore existing data  \n",
    "âœ… **neurOS Integration** - Use NWB data in pipelines  \n",
    "âœ… **Export Results** - Save processing outputs to NWB  \n",
    "âœ… **BIDS Compliance** - Organize datasets properly  \n",
    "\n",
    "## Key Benefits of NWB\n",
    "\n",
    "1. **Standardization** - Common format across labs\n",
    "2. **Metadata** - Rich experimental context\n",
    "3. **Interoperability** - Works with many tools\n",
    "4. **Versioning** - Track data provenance\n",
    "5. **Sharing** - Easy publication to repositories\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "- **Document everything** - Rich metadata is key\n",
    "- **Use standard names** - Follow NWB conventions\n",
    "- **Version control** - Track changes to data\n",
    "- **Test early** - Validate NWB files frequently\n",
    "- **Share openly** - Use platforms like DANDI Archive\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **NWB Homepage**: https://www.nwb.org/\n",
    "- **PyNWB Docs**: https://pynwb.readthedocs.io/\n",
    "- **BIDS Specification**: https://bids.neuroimaging.io/\n",
    "- **DANDI Archive**: https://dandiarchive.org/\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Load real NWB datasets from DANDI\n",
    "- Integrate with other tools (MNE-Python, FieldTrip)\n",
    "- Publish your datasets\n",
    "- Contribute to NWB extensions\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or feedback?** Open an issue on GitHub or check the docs at https://neuros.readthedocs.io\n",
    "\n",
    "**ðŸŽ‰ Congratulations!** You've completed all 6 neurOS tutorials!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
