{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b0b466",
   "metadata": {},
   "source": [
    "# DINOv3 Evaluation on CREMI (ssTEM neurite segmentation)\n",
    "\n",
    "The **CREMI** dataset contains serial section transmission electron microscopy (ssTEM) volumes of the adult *Drosophila* brain. Training samples A, B and C span approximately 5×5×5 μm at 4×4×40 nm resolution and include neurite membrane annotations and synaptic cleft labels【94900813976022†L69-L83】. The challenge evaluates semantic segmentation of neurites and synapses, with performance measured by F1 score and object classification accuracy【479692440647223†L33-L44】.\n",
    "\n",
    "This notebook demonstrates how to use the `neuros` package to extract DINOv3 features and train simple segmentation models. We first show how one might download and load the raw data; if you are running in an environment without internet access you can skip those cells. For demonstration purposes we generate a synthetic dataset that mimics the modality of this dataset and perform a lightweight comparison of two DINOv3 backbones (ConvNeXt-Tiny and ViT-Large) on a binary segmentation task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f096da54",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "If you have network access and the necessary permissions, you can download the dataset using the following commands. These lines are commented out by default to prevent accidental downloads in restricted environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d8362",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Download the CREMI dataset (approx 200 MB).\n",
    "# !wget -O cremi.zip http://hp06.mindhackers.org/rhoana_product/dataset/cremi.zip\n",
    "# !unzip cremi.zip -d ./cremi_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9cd3ec",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The following code shows how you might load the downloaded files into Python. Adjust the paths as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e06175",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example: load HDF5 volumes from CREMI.\n",
    "# import h5py\n",
    "# with h5py.File('cremi_data/sample_A_20160501.hdf', 'r') as f:\n",
    "#     volume = f['volumes/raw'][:]  # numpy array of EM slices\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from neuros.plugins.cv.dinov3_backbone import DINOv3Backbone\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset(num_images: int, size: int = 128, mode: str = \"em\"):\n",
    "    \"\"\"Generate a synthetic dataset for the specified modality.\"\"\"\n",
    "    images, masks = [], []\n",
    "    rng = np.random.default_rng(123)\n",
    "    for _ in range(num_images):\n",
    "        if mode == \"em\":\n",
    "            # Round neurites on noisy background\n",
    "            img = rng.normal(0.5, 0.15, size=(size, size, 1)).clip(0,1)\n",
    "            mask = np.zeros((size,size), int)\n",
    "            for _ in range(rng.integers(3,7)):\n",
    "                cx,cy = rng.integers(0,size,2)\n",
    "                r = rng.integers(size//20, size//10)\n",
    "                Y, X = np.ogrid[:size,:size]\n",
    "                circle = (X-cx)**2 + (Y-cy)**2 <= r**2\n",
    "                mask[circle] = 1\n",
    "                img[circle] += 0.5\n",
    "            img = img.clip(0,1)\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        elif mode == \"mri\":\n",
    "            # Smooth gradient with circular lesion\n",
    "            x = np.linspace(-1,1,size)\n",
    "            y = np.linspace(-1,1,size)\n",
    "            X,Y = np.meshgrid(x,y)\n",
    "            img = 0.5 + 0.5*(X+Y)/2\n",
    "            mask = ((X**2 + Y**2) < 0.2**2).astype(int)\n",
    "            img[mask==1] = 1.0\n",
    "            img_rgb = np.repeat(img[:,:,None],3,axis=2)\n",
    "        elif mode == \"histology\":\n",
    "            # Textured tissue with darker nucleus\n",
    "            base = rng.uniform(0.8,1.0, size=(size,size,3))\n",
    "            noise = rng.normal(0,0.05, size=(size,size,3))\n",
    "            img_rgb = (base + noise).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            cx,cy = rng.integers(size//4,3*size//4,2)\n",
    "            r = size//6\n",
    "            Y,X = np.ogrid[:size,:size]\n",
    "            nucleus = (X-cx)**2 + (Y-cy)**2 <= r**2\n",
    "            mask[nucleus] = 1\n",
    "            img_rgb[nucleus] -= 0.4\n",
    "            img_rgb = img_rgb.clip(0,1)\n",
    "        elif mode == \"connectomics\":\n",
    "            # Curvilinear neurites\n",
    "            img = rng.normal(0.5,0.15,(size,size,1)).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_strands = rng.integers(2,5)\n",
    "            Y = np.arange(size)\n",
    "            for _ in range(num_strands):\n",
    "                amp = rng.uniform(5,20)\n",
    "                freq = rng.uniform(0.02,0.1)\n",
    "                phase = rng.uniform(0,2*np.pi)\n",
    "                center = rng.uniform(size*0.2,size*0.8)\n",
    "                x_vals = center + amp*np.sin(freq*Y + phase)\n",
    "                for y,x_center in enumerate(x_vals.astype(int)):\n",
    "                    x_center = np.clip(x_center, 0, size-1)\n",
    "                    width = rng.integers(size//50, size//30)\n",
    "                    xs = max(x_center - width,0)\n",
    "                    xe = min(x_center + width, size-1)\n",
    "                    mask[y, xs:xe] = 1\n",
    "                    img[y,xs:xe,0] = 1.0\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        elif mode == \"atlas\":\n",
    "            # Coarse anatomical regions with colour shifts\n",
    "            img_rgb = rng.uniform(0.4,0.8,(size,size,3))\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_regions = rng.integers(3,6)\n",
    "            centers = rng.integers(size//4,3*size//4,(num_regions,2))\n",
    "            radii = rng.integers(size//10,size//5,num_regions)\n",
    "            labels = rng.permutation(num_regions)\n",
    "            Y,X = np.ogrid[:size,:size]\n",
    "            for idx,(cx,cy) in enumerate(centers):\n",
    "                region = (X-cx)**2 + (Y-cy)**2 <= radii[idx]**2\n",
    "                mask[region] = labels[idx] + 1\n",
    "                color_shift = rng.uniform(-0.1,0.1,3)\n",
    "                img_rgb[region] = np.clip(img_rgb[region] + color_shift,0,1)\n",
    "        elif mode == \"calcium\":\n",
    "            # Bright circular ROIs on noisy background\n",
    "            img = rng.normal(0.4,0.1,(size,size,1)).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_cells = rng.integers(3,8)\n",
    "            for _ in range(num_cells):\n",
    "                cx,cy = rng.integers(0,size,2)\n",
    "                r = rng.integers(size//30,size//15)\n",
    "                Y,X = np.ogrid[:size,:size]\n",
    "                cell = (X-cx)**2 + (Y-cy)**2 <= r**2\n",
    "                mask[cell] = 1\n",
    "                img[cell] += 0.6\n",
    "            img = img.clip(0,1)\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        elif mode == \"tracking\":\n",
    "            # Overlapping ellipses representing cells\n",
    "            img = rng.normal(0.5,0.1,(size,size,1)).clip(0,1)\n",
    "            mask = np.zeros((size,size),int)\n",
    "            num_cells = rng.integers(5,10)\n",
    "            for label in range(1,num_cells+1):\n",
    "                cx,cy = rng.integers(0,size,2)\n",
    "                rx = rng.integers(size//40,size//20)\n",
    "                ry = rng.integers(size//40,size//20)\n",
    "                angle = rng.uniform(0,np.pi)\n",
    "                Yg,Xg = np.ogrid[:size,:size]\n",
    "                x_rot = (Xg-cx)*np.cos(angle)+(Yg-cy)*np.sin(angle)\n",
    "                y_rot = -(Xg-cx)*np.sin(angle)+(Yg-cy)*np.cos(angle)\n",
    "                ellipse = (x_rot/rx)**2 + (y_rot/ry)**2 <= 1\n",
    "                mask[ellipse] = 1\n",
    "                img[ellipse] += 0.5\n",
    "            img = img.clip(0,1)\n",
    "            img_rgb = np.repeat(img,3,axis=2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}\")\n",
    "        images.append((img_rgb*255).astype(np.uint8))\n",
    "        masks.append((mask>0).astype(int))\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def flatten_dataset(images, masks, backbone):\n",
    "    \"\"\"Flatten patch features and binary labels for a dataset.\"\"\"\n",
    "    all_feats, all_labels = [], []\n",
    "    for img, mask in zip(images, masks):\n",
    "        pf = backbone.embed([img])[0]\n",
    "        gs = backbone.grid_size\n",
    "        ps = backbone.patch_size\n",
    "        mask_crop = mask[:gs*ps, :gs*ps]\n",
    "        patch_mask = mask_crop.reshape(gs, ps, gs, ps)\n",
    "        labels = (patch_mask.sum(axis=(1,3)) > (ps*ps/2)).astype(int)\n",
    "        all_feats.append(pf)\n",
    "        all_labels.append(labels.flatten())\n",
    "    return np.concatenate(all_feats), np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "def evaluate_backbones(mode: str):\n",
    "    \"\"\"Train and evaluate ConvNeXt-Tiny and ViT-Large on the given synthetic modality.\"\"\"\n",
    "    results = {}\n",
    "    for back_name, model_id in [\n",
    "        ('CNX-T', 'facebook/dinov3-convnext-tiny-pretrain-lvd1689m'),\n",
    "        ('ViT-L', 'facebook/dinov3-vit-large-pretrain-lvd1689m')\n",
    "    ]:\n",
    "        backbone = DINOv3Backbone(model_id=model_id)\n",
    "        # generate a small training and test set\n",
    "        train_images, train_masks = generate_synthetic_dataset(8, mode=mode)\n",
    "        test_images, test_masks = generate_synthetic_dataset(4, mode=mode)\n",
    "        X_train, y_train = flatten_dataset(train_images, train_masks, backbone)\n",
    "        X_test, y_test = flatten_dataset(test_images, test_masks, backbone)\n",
    "        # handle single class case\n",
    "        if len(np.unique(y_train)) < 2:\n",
    "            majority = y_train[0]\n",
    "            preds = np.full_like(y_test, majority)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            clf = LogisticRegression(max_iter=300)\n",
    "            clf.fit(X_train, y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            f1 = f1_score(y_test, preds)\n",
    "        results[back_name] = (acc, f1)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9df291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate DINOv3 backbones on a synthetic representation of this dataset\n",
    "results = evaluate_backbones(\"em\")\n",
    "for model, (acc, f1) in results.items():\n",
    "    print(f\"{model} accuracy: {acc:.3f}, F1 score: {f1:.3f}\")\n",
    "\n",
    "models = list(results.keys())\n",
    "accs = [results[m][0] for m in models]\n",
    "f1s = [results[m][1] for m in models]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(models, accs)\n",
    "plt.title(\"Segmentation accuracy on synthetic em dataset\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(models, f1s)\n",
    "plt.title(\"F1 score on synthetic em dataset\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
