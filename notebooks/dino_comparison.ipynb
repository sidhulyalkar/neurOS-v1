{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0250c61c",
   "metadata": {},
   "source": [
    "# Comparing DINOv3 Backbones within neurOS\n",
    "\n",
    "This notebook demonstrates how to integrate the **DINOv3** backbone into the\n",
    "`neurOS` framework and how to compare different model sizes on synthetic\n",
    "neuroscience datasets.  We implement a simple segmentation task where the\n",
    "goal is to predict a binary mask (foreground vs. background) from image\n",
    "patches.  Although the backbone here is a deterministic placeholder, the\n",
    "pipeline mirrors what you would do with real DINOv3 weights:\n",
    "\n",
    "1. Instantiate the backbone for a given variant (e.g. ConvNeXt‑Tiny or ViT‑Large).\n",
    "2. Generate or load images and corresponding binary masks.\n",
    "3. Extract patch features for each image.\n",
    "4. Train a classifier (here, logistic regression) on the patch features.\n",
    "5. Evaluate the classifier on a held‑out test set using metrics like\n",
    "   accuracy and F1 score.\n",
    "\n",
    "We repeat this procedure for three synthetic modalities—electron microscopy\n",
    "(EM), MRI and histology—and compare the performance of the **CNX‑Tiny** and\n",
    "**ViT‑Large** variants.  Because the features are randomised, any\n",
    "difference you observe is due to chance; however the example shows how to\n",
    "structure your experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a362ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from neuros.plugins.cv.dinov3_backbone import DINOv3Backbone\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset(num_images: int, size: int = 256, mode: str = \"em\"):\n",
    "    '''\n",
    "    Generate a synthetic dataset of images and binary masks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_images: int\n",
    "        Number of images to generate.\n",
    "    size: int, optional\n",
    "        Spatial resolution of the square images.\n",
    "    mode: str, optional\n",
    "        The type of modality to simulate.  Supported values are:\n",
    "        ``\"em\"`` for electron microscopy (random noise with sparse spots),\n",
    "        ``\"mri\"`` for MRI (smooth gradient with circular lesion) and\n",
    "        ``\"histology\"`` for histology (textured background with blob).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images: list of numpy.ndarray\n",
    "        RGB images with pixel values in [0, 255].\n",
    "    masks: list of numpy.ndarray\n",
    "        Binary masks of shape (H, W) with values 0 or 1.\n",
    "    '''\n",
    "    images = []\n",
    "    masks = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    for i in range(num_images):\n",
    "        if mode == \"em\":\n",
    "            # EM: random noise with bright circular spots\n",
    "            img = rng.normal(loc=0.5, scale=0.15, size=(size, size, 1)).clip(0, 1)\n",
    "            num_spots = rng.integers(3, 7)\n",
    "            mask = np.zeros((size, size), dtype=np.int32)\n",
    "            for _ in range(num_spots):\n",
    "                cx, cy = rng.integers(0, size, size=2)\n",
    "                r = rng.integers(size//20, size//10)\n",
    "                Y, X = np.ogrid[:size, :size]\n",
    "                circle = (X - cx)**2 + (Y - cy)**2 <= r**2\n",
    "                mask[circle] = 1\n",
    "                img[circle] += 0.5\n",
    "            img = img.clip(0, 1)\n",
    "            img_rgb = np.repeat(img, 3, axis=2)\n",
    "        elif mode == \"mri\":\n",
    "            # MRI: smooth gradient with circular lesion\n",
    "            x = np.linspace(-1, 1, size)\n",
    "            y = np.linspace(-1, 1, size)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            img = 0.5 + 0.5 * (X + Y) / 2\n",
    "            mask = ((X**2 + Y**2) < 0.2**2).astype(np.int32)\n",
    "            img[mask == 1] = 1.0\n",
    "            img_rgb = np.repeat(img[:, :, None], 3, axis=2)\n",
    "        elif mode == \"histology\":\n",
    "            # Histology: pinkish texture with darker nucleus region\n",
    "            base = rng.uniform(0.8, 1.0, size=(size, size, 3))\n",
    "            noise = rng.normal(0, 0.05, size=(size, size, 3))\n",
    "            img_rgb = (base + noise).clip(0, 1)\n",
    "            cx, cy = rng.integers(size//4, 3*size//4, size=2)\n",
    "            r = size // 6\n",
    "            mask = np.zeros((size, size), dtype=np.int32)\n",
    "            Y, X = np.ogrid[:size, :size]\n",
    "            nucleus = (X - cx)**2 + (Y - cy)**2 <= r**2\n",
    "            mask[nucleus] = 1\n",
    "            img_rgb[nucleus] -= 0.4\n",
    "            img_rgb = img_rgb.clip(0, 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported mode: {mode}\")\n",
    "        images.append((img_rgb * 255).astype(np.uint8))\n",
    "        masks.append(mask)\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def flatten_dataset(images, masks, backbone):\n",
    "    '''\n",
    "    Convert images and masks into patch features and labels for classifier training.\n",
    "\n",
    "    Each patch is assigned the majority label of the underlying mask.  The\n",
    "    features are extracted using the provided backbone.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images: list of numpy.ndarray\n",
    "        List of RGB images.\n",
    "    masks: list of numpy.ndarray\n",
    "        Corresponding binary masks.\n",
    "    backbone: DINOv3Backbone\n",
    "        Backbone instance used to produce features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features: numpy.ndarray\n",
    "        Array of shape (M, C) where M is the total number of patches across\n",
    "        images and C is the feature dimension.\n",
    "    labels: numpy.ndarray\n",
    "        Binary labels of length M.\n",
    "    '''\n",
    "    all_feats = []\n",
    "    all_labels = []\n",
    "    for img, mask in zip(images, masks):\n",
    "        patch_feats = backbone.embed([img])[0]  # (N, C)\n",
    "        grid_size = backbone.grid_size\n",
    "        # Downsample mask to patch grid by majority voting\n",
    "        h_patch = backbone.patch_size\n",
    "        w_patch = backbone.patch_size\n",
    "        mask_cropped = mask[: grid_size * h_patch, : grid_size * w_patch]\n",
    "        patch_mask = mask_cropped.reshape(grid_size, h_patch, grid_size, w_patch)\n",
    "        # Majority vote for each patch\n",
    "        patch_labels = (patch_mask.sum(axis=(1, 3)) > (h_patch * w_patch / 2)).astype(np.int32)\n",
    "        all_feats.append(patch_feats)\n",
    "        all_labels.append(patch_labels.flatten())\n",
    "    return np.concatenate(all_feats, axis=0), np.concatenate(all_labels, axis=0)\n",
    "\n",
    "\n",
    "def train_and_evaluate(backbone_id, mode):\n",
    "    '''\n",
    "    Train a logistic regression on patch features and evaluate on test data.\n",
    "\n",
    "    Returns accuracy and F1 score.\n",
    "    '''\n",
    "    backbone = DINOv3Backbone(model_id=backbone_id)\n",
    "    # Generate dataset\n",
    "    images, masks = generate_synthetic_dataset(12, size=128, mode=mode)\n",
    "    # Split into train and test\n",
    "    train_images = images[:8]\n",
    "    train_masks = masks[:8]\n",
    "    test_images = images[8:]\n",
    "    test_masks = masks[8:]\n",
    "    # Extract features and labels\n",
    "    X_train, y_train = flatten_dataset(train_images, train_masks, backbone)\n",
    "    X_test, y_test = flatten_dataset(test_images, test_masks, backbone)\n",
    "    # If only one class in training data, return trivial baseline\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        # Predict the majority class for test set\n",
    "        majority = y_train[0] if len(y_train) > 0 else 0\n",
    "        preds = np.full_like(y_test, majority)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        f1 = 0.0  # F1 is undefined when only one class exists; set to zero\n",
    "        return acc, f1\n",
    "    # Train logistic regression\n",
    "    clf = LogisticRegression(max_iter=200)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Evaluate\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cfc87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CNX‑Tiny and ViT‑Large on each modality\n",
    "results = {}\n",
    "modalities = [\"em\", \"mri\", \"histology\"]\n",
    "model_variants = {\"CNX-Tiny\": \"cnx-tiny\", \"ViT-Large\": \"vit-large\"}\n",
    "for mod in modalities:\n",
    "    results[mod] = {}\n",
    "    for name, model_id in model_variants.items():\n",
    "        acc, f1 = train_and_evaluate(model_id, mod)\n",
    "        results[mod][name] = {\"accuracy\": acc, \"f1\": f1}\n",
    "        print(f\"{name} on {mod}: accuracy={acc:.3f}, F1={f1:.3f}\")\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar charts of accuracy and F1 score\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "for i, metric in enumerate([\"accuracy\", \"f1\"]):\n",
    "    ax = axes[i]\n",
    "    bars = []\n",
    "    labels = []\n",
    "    for mod in modalities:\n",
    "        for name in model_variants.keys():\n",
    "            bars.append(results[mod][name][metric])\n",
    "            labels.append(f\"{mod}-{name.split('-')[0]}\")\n",
    "    ax.bar(range(len(bars)), bars)\n",
    "    ax.set_xticks(range(len(bars)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_ylabel(metric.capitalize())\n",
    "    ax.set_title(f\"{metric.capitalize()} by modality and model\")\n",
    "    ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
