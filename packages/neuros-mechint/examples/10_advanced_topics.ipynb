{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 10: Advanced Topics in Mechanistic Interpretability\n",
    "\n",
    "## Beyond the Basics: Cutting-Edge Interpretability Methods\n",
    "\n",
    "This final notebook explores **advanced topics** that push the boundaries of mechanistic interpretability:\n",
    "- **Meta-dynamics**: How representations evolve during training\n",
    "- **Manifold Geometry**: Shape and curvature of representational spaces\n",
    "- **Topological Analysis**: Persistent homology and Betti numbers\n",
    "- **Counterfactual Interventions**: What-if experiments on networks\n",
    "\n",
    "### Why Advanced Methods Matter\n",
    "\n",
    "1. **Training Dynamics**: Understand how and when networks learn\n",
    "2. **Geometric Structure**: Reveal intrinsic organization of representations\n",
    "3. **Robust Analysis**: Topology is invariant to smooth deformations\n",
    "4. **Causal Understanding**: Counterfactuals reveal causal mechanisms\n",
    "5. **Phase Transitions**: Identify critical moments in learning\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Meta-Dynamics Analysis**: Track training trajectories in representation space\n",
    "2. **Manifold Curvature**: Measure local geometry of neural representations\n",
    "3. **Persistent Homology**: Detect topological features (holes, loops, voids)\n",
    "4. **Counterfactual Interventions**: Do-calculus and latent surgery\n",
    "5. **Feature Emergence Detection**: When do concepts crystallize?\n",
    "6. **Representational Drift**: How representations change over time\n",
    "\n",
    "### References\n",
    "\n",
    "- Achille & Soatto (2018): *Emergence of invariance and disentanglement in deep representations*\n",
    "- Chung et al. (2018): *Classification and geometry of general perceptual manifolds*\n",
    "- Naitzat et al. (2020): *Topology of deep neural networks*\n",
    "- Pearl (2009): *Causality: Models, Reasoning, and Inference*\n",
    "- Geirhos et al. (2020): *Beyond accuracy: Quantifying trial-by-trial behaviour*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import copy\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Meta-Dynamics - Tracking Training Trajectories\n",
    "\n",
    "### What are Meta-Dynamics?\n",
    "\n",
    "**Meta-dynamics** studies how neural representations change during training:\n",
    "- Not just \"does the model learn?\" but **\"how does learning unfold?\"**\n",
    "- Track checkpoints throughout training\n",
    "- Analyze representational trajectories\n",
    "- Detect phase transitions and critical periods\n",
    "\n",
    "### Key Questions\n",
    "\n",
    "1. **When do features emerge?** At what point does the network discover concepts?\n",
    "2. **Are there phases?** Distinct stages of learning (e.g., fitting → compression)\n",
    "3. **What order?** Do simple features emerge before complex ones?\n",
    "4. **Representational drift**: Do representations keep changing after convergence?\n",
    "\n",
    "### Metrics for Tracking\n",
    "\n",
    "1. **Representational Similarity**: CKA, CCA, RSA between checkpoints\n",
    "2. **Feature Selectivity**: How selective are neurons to task variables?\n",
    "3. **Dimensionality**: Participation ratio, intrinsic dimension\n",
    "4. **Alignment**: How well do representations align with brain/behavior?\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Curriculum learning**: Train on easy examples first\n",
    "- **Early stopping**: Stop when representations stop improving\n",
    "- **Architecture search**: Identify when capacity is saturated\n",
    "- **Transfer learning**: Choose which checkpoint to transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingTrajectoryAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze how representations evolve during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.checkpoints = []\n",
    "        self.metrics_history = {\n",
    "            'loss': [],\n",
    "            'accuracy': [],\n",
    "            'dimensionality': [],\n",
    "            'similarity_to_init': []\n",
    "        }\n",
    "    \n",
    "    def save_checkpoint(self, model, epoch, loss, accuracy):\n",
    "        \"\"\"\n",
    "        Save model checkpoint and compute metrics.\n",
    "        \"\"\"\n",
    "        # Deep copy model state\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': copy.deepcopy(model.state_dict()),\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        self.checkpoints.append(checkpoint)\n",
    "        \n",
    "        # Record metrics\n",
    "        self.metrics_history['loss'].append(loss)\n",
    "        self.metrics_history['accuracy'].append(accuracy)\n",
    "    \n",
    "    def compute_representation_similarity(self, model1, model2, X):\n",
    "        \"\"\"\n",
    "        Compute similarity between representations from two models.\n",
    "        \n",
    "        Uses Centered Kernel Alignment (CKA).\n",
    "        \"\"\"\n",
    "        # Get representations\n",
    "        with torch.no_grad():\n",
    "            repr1 = self._get_representation(model1, X)\n",
    "            repr2 = self._get_representation(model2, X)\n",
    "        \n",
    "        # Compute CKA\n",
    "        cka = self._linear_cka(repr1, repr2)\n",
    "        return cka\n",
    "    \n",
    "    def _get_representation(self, model, X):\n",
    "        \"\"\"Extract penultimate layer representation.\"\"\"\n",
    "        activation = None\n",
    "        \n",
    "        def hook_fn(module, input, output):\n",
    "            nonlocal activation\n",
    "            activation = output\n",
    "        \n",
    "        # Find penultimate layer\n",
    "        layers = [m for m in model.modules() if isinstance(m, nn.Linear)]\n",
    "        if len(layers) >= 2:\n",
    "            handle = layers[-2].register_forward_hook(hook_fn)\n",
    "        else:\n",
    "            handle = layers[-1].register_forward_hook(hook_fn)\n",
    "        \n",
    "        _ = model(X)\n",
    "        handle.remove()\n",
    "        \n",
    "        return activation.cpu().numpy()\n",
    "    \n",
    "    def _linear_cka(self, X, Y):\n",
    "        \"\"\"\n",
    "        Compute Linear CKA similarity.\n",
    "        \n",
    "        CKA(X, Y) = ||X^T Y||_F^2 / (||X^T X||_F * ||Y^T Y||_F)\n",
    "        \"\"\"\n",
    "        # Center\n",
    "        X = X - X.mean(axis=0)\n",
    "        Y = Y - Y.mean(axis=0)\n",
    "        \n",
    "        # Gram matrices\n",
    "        XTX = X.T @ X\n",
    "        YTY = Y.T @ Y\n",
    "        XTY = X.T @ Y\n",
    "        \n",
    "        # CKA\n",
    "        numerator = np.linalg.norm(XTY, 'fro')**2\n",
    "        denominator = np.linalg.norm(XTX, 'fro') * np.linalg.norm(YTY, 'fro')\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        \n",
    "        return numerator / denominator\n",
    "    \n",
    "    def compute_dimensionality(self, model, X):\n",
    "        \"\"\"\n",
    "        Compute effective dimensionality (participation ratio).\n",
    "        \"\"\"\n",
    "        repr = self._get_representation(model, X)\n",
    "        \n",
    "        # Covariance\n",
    "        cov = np.cov(repr.T)\n",
    "        eigvals = np.linalg.eigvalsh(cov)\n",
    "        eigvals = np.maximum(eigvals, 0)\n",
    "        \n",
    "        # Participation ratio\n",
    "        if np.sum(eigvals**2) == 0:\n",
    "            return 0\n",
    "        pr = np.sum(eigvals)**2 / np.sum(eigvals**2)\n",
    "        \n",
    "        return pr\n",
    "    \n",
    "    def analyze_trajectory(self, X):\n",
    "        \"\"\"\n",
    "        Analyze full training trajectory.\n",
    "        \n",
    "        Computes:\n",
    "        - Similarity to initialization\n",
    "        - Dimensionality over time\n",
    "        - Phase detection\n",
    "        \"\"\"\n",
    "        if len(self.checkpoints) < 2:\n",
    "            print(\"Need at least 2 checkpoints\")\n",
    "            return\n",
    "        \n",
    "        print(\"Analyzing training trajectory...\")\n",
    "        \n",
    "        # Load first checkpoint (initialization)\n",
    "        init_model = self._load_checkpoint(0)\n",
    "        \n",
    "        # Analyze each checkpoint\n",
    "        for i, checkpoint in enumerate(self.checkpoints):\n",
    "            model = self._load_checkpoint(i)\n",
    "            \n",
    "            # Similarity to init\n",
    "            sim = self.compute_representation_similarity(init_model, model, X)\n",
    "            self.metrics_history['similarity_to_init'].append(sim)\n",
    "            \n",
    "            # Dimensionality\n",
    "            dim = self.compute_dimensionality(model, X)\n",
    "            self.metrics_history['dimensionality'].append(dim)\n",
    "        \n",
    "        print(\"Analysis complete!\")\n",
    "    \n",
    "    def _load_checkpoint(self, idx):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        # This is a simplified version - in practice, need to know architecture\n",
    "        # For now, return placeholder\n",
    "        checkpoint = self.checkpoints[idx]\n",
    "        return checkpoint  # Return state dict\n",
    "\n",
    "print(\"Training trajectory analyzer implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate with synthetic training trajectory\n",
    "# Simulate how metrics evolve during training\n",
    "\n",
    "def simulate_training_trajectory(n_epochs=100):\n",
    "    \"\"\"\n",
    "    Simulate realistic training trajectory.\n",
    "    \"\"\"\n",
    "    epochs = np.arange(n_epochs)\n",
    "    \n",
    "    # Loss: Exponential decay with noise\n",
    "    loss = 2.0 * np.exp(-epochs / 20) + 0.5 + 0.1 * np.random.randn(n_epochs)\n",
    "    loss = np.maximum(loss, 0.3)  # Floor\n",
    "    \n",
    "    # Accuracy: Sigmoid growth\n",
    "    accuracy = 1.0 / (1 + np.exp(-(epochs - 30) / 10))\n",
    "    accuracy = 0.5 + 0.4 * accuracy + 0.02 * np.random.randn(n_epochs)\n",
    "    \n",
    "    # Dimensionality: Two phases\n",
    "    # Phase 1 (0-40): Increasing (fitting)\n",
    "    # Phase 2 (40+): Decreasing (compression)\n",
    "    dim_phase1 = 10 + 20 * (epochs / 40)\n",
    "    dim_phase2 = 30 - 10 * ((epochs - 40) / 60)\n",
    "    dimensionality = np.where(epochs < 40, dim_phase1, dim_phase2)\n",
    "    dimensionality += np.random.randn(n_epochs) * 2\n",
    "    dimensionality = np.maximum(dimensionality, 5)\n",
    "    \n",
    "    # Similarity to init: Decreasing (representations drift)\n",
    "    similarity = np.exp(-epochs / 30) + 0.1 * np.random.randn(n_epochs)\n",
    "    similarity = np.clip(similarity, 0, 1)\n",
    "    \n",
    "    return {\n",
    "        'epochs': epochs,\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'dimensionality': dimensionality,\n",
    "        'similarity_to_init': similarity\n",
    "    }\n",
    "\n",
    "# Generate trajectory\n",
    "trajectory = simulate_training_trajectory(n_epochs=100)\n",
    "\n",
    "print(\"Simulated training trajectory generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training trajectory\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs = trajectory['epochs']\n",
    "\n",
    "# Plot 1: Loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(epochs, trajectory['loss'], linewidth=2, color='red')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy\n",
    "ax = axes[0, 1]\n",
    "ax.plot(epochs, trajectory['accuracy'], linewidth=2, color='green')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Test Accuracy')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Dimensionality (shows two phases)\n",
    "ax = axes[1, 0]\n",
    "ax.plot(epochs, trajectory['dimensionality'], linewidth=2, color='blue')\n",
    "ax.axvline(x=40, color='red', linestyle='--', linewidth=2, \n",
    "           label='Phase transition')\n",
    "ax.annotate('Fitting\\n(increasing dim)', xy=(20, 25), fontsize=10, ha='center')\n",
    "ax.annotate('Compression\\n(decreasing dim)', xy=(70, 25), fontsize=10, ha='center')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Effective Dimensionality')\n",
    "ax.set_title('Representational Dimensionality (Two-Phase Learning)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Similarity to initialization\n",
    "ax = axes[1, 1]\n",
    "ax.plot(epochs, trajectory['similarity_to_init'], linewidth=2, color='purple')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('CKA Similarity')\n",
    "ax.set_title('Representational Drift from Initialization')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Loss decreases, accuracy increases (expected)\")\n",
    "print(\"- Dimensionality: Fitting phase (epoch 0-40), then compression (40+)\")\n",
    "print(\"- Representations drift away from initialization\")\n",
    "print(\"- Phase transition around epoch 40 (critical period)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Manifold Geometry - Curvature and Shape\n",
    "\n",
    "### What is Manifold Geometry?\n",
    "\n",
    "Neural representations often lie on low-dimensional **manifolds** embedded in high-dimensional space.\n",
    "\n",
    "**Geometric properties** reveal structure:\n",
    "- **Curvature**: How \"bent\" is the manifold?\n",
    "- **Geodesic distance**: Shortest path along manifold\n",
    "- **Local dimension**: Dimensionality in neighborhoods\n",
    "- **Tangent spaces**: Local linear approximations\n",
    "\n",
    "### Why Geometry Matters\n",
    "\n",
    "1. **Separability**: Curved manifolds can separate classes linearly\n",
    "2. **Generalization**: Smooth manifolds generalize better\n",
    "3. **Capacity**: Geometry reveals network expressivity\n",
    "4. **Alignment**: Compare geometries (brain vs model)\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "1. **Gaussian Curvature**: Intrinsic curvature (positive = sphere-like, negative = saddle)\n",
    "2. **Geodesic Distance**: Path length along manifold\n",
    "3. **Tangent Alignment**: How aligned are local tangent spaces?\n",
    "4. **Manifold Capacity**: How many patterns can be separated?\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Architecture design**: Encourage smooth manifolds\n",
    "- **Transfer learning**: Match manifold geometries\n",
    "- **Neuroscience**: Compare to neural manifolds\n",
    "- **Robustness**: Smooth manifolds are more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManifoldGeometryAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze geometric properties of neural representation manifolds.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def estimate_curvature(self, X, k=10):\n",
    "        \"\"\"\n",
    "        Estimate local Gaussian curvature using PCA in neighborhoods.\n",
    "        \n",
    "        Intuition: High curvature = local PCA has rapidly changing directions\n",
    "        \"\"\"\n",
    "        n_samples, n_dims = X.shape\n",
    "        \n",
    "        # Find k nearest neighbors\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1).fit(X)\n",
    "        distances, indices = nbrs.kneighbors(X)\n",
    "        \n",
    "        curvatures = []\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            # Get neighborhood\n",
    "            neighbor_indices = indices[i, 1:]  # Exclude self\n",
    "            neighborhood = X[neighbor_indices]\n",
    "            \n",
    "            # Center\n",
    "            centered = neighborhood - neighborhood.mean(axis=0)\n",
    "            \n",
    "            # PCA\n",
    "            if len(centered) > 1:\n",
    "                cov = centered.T @ centered / len(centered)\n",
    "                eigvals = np.linalg.eigvalsh(cov)\n",
    "                eigvals = np.maximum(eigvals, 0)\n",
    "                \n",
    "                # Curvature estimate: ratio of small to large eigenvalues\n",
    "                if eigvals[-1] > 1e-10:\n",
    "                    curvature = eigvals[0] / eigvals[-1]\n",
    "                else:\n",
    "                    curvature = 0\n",
    "            else:\n",
    "                curvature = 0\n",
    "            \n",
    "            curvatures.append(curvature)\n",
    "        \n",
    "        return np.array(curvatures)\n",
    "    \n",
    "    def compute_geodesic_distance(self, X, metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Estimate geodesic distances using Isomap-like approach.\n",
    "        \"\"\"\n",
    "        # Pairwise distances\n",
    "        dists = squareform(pdist(X, metric=metric))\n",
    "        \n",
    "        # Use shortest path (Floyd-Warshall or Dijkstra)\n",
    "        # For simplicity, just return Euclidean distances\n",
    "        # In practice, would build k-NN graph and compute graph distances\n",
    "        \n",
    "        return dists\n",
    "    \n",
    "    def compute_manifold_dimension(self, X, n_neighbors=10):\n",
    "        \"\"\"\n",
    "        Estimate local intrinsic dimensionality using MLE.\n",
    "        \"\"\"\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors+1).fit(X)\n",
    "        distances, _ = nbrs.kneighbors(X)\n",
    "        \n",
    "        # Remove self (distance 0)\n",
    "        distances = distances[:, 1:]\n",
    "        \n",
    "        # MLE dimension estimate\n",
    "        r_k = distances[:, -1]\n",
    "        r_1 = distances[:, 0]\n",
    "        \n",
    "        ratio = r_k / (r_1 + 1e-10)\n",
    "        ratio = np.maximum(ratio, 1e-10)\n",
    "        \n",
    "        dims = (n_neighbors - 1) / np.log(ratio)\n",
    "        dims = dims[np.isfinite(dims)]\n",
    "        \n",
    "        return np.median(dims) if len(dims) > 0 else 0\n",
    "    \n",
    "    def analyze_manifold(self, X):\n",
    "        \"\"\"\n",
    "        Complete manifold analysis.\n",
    "        \"\"\"\n",
    "        print(\"Analyzing manifold geometry...\")\n",
    "        \n",
    "        # Curvature\n",
    "        curvatures = self.estimate_curvature(X, k=10)\n",
    "        mean_curvature = np.mean(curvatures)\n",
    "        std_curvature = np.std(curvatures)\n",
    "        \n",
    "        # Intrinsic dimension\n",
    "        intrinsic_dim = self.compute_manifold_dimension(X, n_neighbors=10)\n",
    "        \n",
    "        results = {\n",
    "            'mean_curvature': mean_curvature,\n",
    "            'std_curvature': std_curvature,\n",
    "            'curvatures': curvatures,\n",
    "            'intrinsic_dimension': intrinsic_dim,\n",
    "            'ambient_dimension': X.shape[1]\n",
    "        }\n",
    "        \n",
    "        print(f\"  Mean curvature: {mean_curvature:.4f}\")\n",
    "        print(f\"  Intrinsic dimension: {intrinsic_dim:.2f}\")\n",
    "        print(f\"  Ambient dimension: {X.shape[1]}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"Manifold geometry analyzer implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic manifold data\n",
    "def generate_swiss_roll(n_samples=1000, noise=0.1):\n",
    "    \"\"\"\n",
    "    Generate Swiss roll: classic 2D manifold in 3D space.\n",
    "    \"\"\"\n",
    "    t = 1.5 * np.pi * (1 + 2 * np.random.rand(n_samples))\n",
    "    x = t * np.cos(t)\n",
    "    y = 20 * np.random.rand(n_samples)\n",
    "    z = t * np.sin(t)\n",
    "    \n",
    "    X = np.vstack([x, y, z]).T\n",
    "    X += noise * np.random.randn(n_samples, 3)\n",
    "    \n",
    "    return X, t  # Return both data and parameter\n",
    "\n",
    "# Generate data\n",
    "X_manifold, t_param = generate_swiss_roll(n_samples=500, noise=0.1)\n",
    "\n",
    "print(f\"Generated Swiss roll manifold:\")\n",
    "print(f\"  Samples: {X_manifold.shape[0]}\")\n",
    "print(f\"  Ambient dimension: {X_manifold.shape[1]} (3D)\")\n",
    "print(f\"  True intrinsic dimension: 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze manifold\n",
    "analyzer = ManifoldGeometryAnalyzer()\n",
    "manifold_results = analyzer.analyze_manifold(X_manifold)\n",
    "\n",
    "print(\"\\nManifold Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize manifold\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: 3D scatter (ambient space)\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "scatter = ax1.scatter(X_manifold[:, 0], X_manifold[:, 1], X_manifold[:, 2],\n",
    "                     c=t_param, cmap='viridis', s=10, alpha=0.6)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title('Swiss Roll in 3D (Ambient Space)')\n",
    "plt.colorbar(scatter, ax=ax1, label='Parameter t')\n",
    "\n",
    "# Plot 2: Curvature distribution\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.hist(manifold_results['curvatures'], bins=30, alpha=0.7, color='steelblue')\n",
    "ax2.axvline(x=manifold_results['mean_curvature'], color='red', \n",
    "           linestyle='--', linewidth=2, label=f'Mean: {manifold_results[\"mean_curvature\"]:.3f}')\n",
    "ax2.set_xlabel('Local Curvature')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Curvature Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Curvature on manifold\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "scatter2 = ax3.scatter(X_manifold[:, 0], X_manifold[:, 1], X_manifold[:, 2],\n",
    "                      c=manifold_results['curvatures'], cmap='RdYlBu_r',\n",
    "                      s=20, alpha=0.7)\n",
    "ax3.set_xlabel('X')\n",
    "ax3.set_ylabel('Y')\n",
    "ax3.set_zlabel('Z')\n",
    "ax3.set_title('Curvature on Manifold\\n(Red=high, Blue=low)')\n",
    "plt.colorbar(scatter2, ax=ax3, label='Curvature')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Swiss roll is 2D manifold embedded in 3D\")\n",
    "print(f\"- Estimated intrinsic dimension: {manifold_results['intrinsic_dimension']:.1f} (should be ≈ 2)\")\n",
    "print(\"- Curvature varies across manifold (higher at tighter curves)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Counterfactual Interventions\n",
    "\n",
    "### What are Counterfactuals?\n",
    "\n",
    "**Counterfactual reasoning**: \"What would happen if...?\"\n",
    "\n",
    "For neural networks:\n",
    "- **Question**: What if neuron X had a different value?\n",
    "- **Method**: Surgically modify activation, observe downstream effects\n",
    "- **Goal**: Understand causal role of each component\n",
    "\n",
    "### Types of Interventions\n",
    "\n",
    "1. **Latent Surgery**: Directly modify hidden representations\n",
    "2. **Do-Calculus**: Pearl's causal intervention framework\n",
    "3. **Synthetic Lesions**: Ablate neurons or connections\n",
    "4. **Causal Tracing**: Track information flow through network\n",
    "\n",
    "### Why Counterfactuals Matter\n",
    "\n",
    "1. **Causality**: Correlation ≠ causation, interventions reveal true causes\n",
    "2. **Interpretability**: Understand functional role of components\n",
    "3. **Debugging**: Identify failure modes\n",
    "4. **Control**: Steer network behavior\n",
    "\n",
    "### Pearl's Causal Hierarchy\n",
    "\n",
    "1. **Association**: P(Y|X) - Seeing/observing\n",
    "2. **Intervention**: P(Y|do(X)) - Doing/intervening\n",
    "3. **Counterfactual**: P(Y_X|X',Y') - Imagining/reasoning\n",
    "\n",
    "Neural networks typically studied at level 1, but levels 2-3 are more powerful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterfactualAnalyzer:\n",
    "    \"\"\"\n",
    "    Perform counterfactual interventions on neural networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def latent_surgery(self, x, layer_name, neuron_idx, new_value):\n",
    "        \"\"\"\n",
    "        Perform latent surgery: modify specific neuron activation.\n",
    "        \n",
    "        Args:\n",
    "            x: Input\n",
    "            layer_name: Which layer to modify\n",
    "            neuron_idx: Which neuron to modify\n",
    "            new_value: New activation value\n",
    "        \n",
    "        Returns:\n",
    "            output_original: Output without intervention\n",
    "            output_intervened: Output with intervention\n",
    "        \"\"\"\n",
    "        # Get original output\n",
    "        with torch.no_grad():\n",
    "            output_original = self.model(x)\n",
    "        \n",
    "        # Intervention hook\n",
    "        def intervention_hook(module, input, output):\n",
    "            # Modify specific neuron\n",
    "            output[:, neuron_idx] = new_value\n",
    "            return output\n",
    "        \n",
    "        # Find layer and register hook\n",
    "        target_layer = None\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == layer_name:\n",
    "                target_layer = module\n",
    "                break\n",
    "        \n",
    "        if target_layer is None:\n",
    "            raise ValueError(f\"Layer {layer_name} not found\")\n",
    "        \n",
    "        handle = target_layer.register_forward_hook(intervention_hook)\n",
    "        \n",
    "        # Get intervened output\n",
    "        with torch.no_grad():\n",
    "            output_intervened = self.model(x)\n",
    "        \n",
    "        # Remove hook\n",
    "        handle.remove()\n",
    "        \n",
    "        return output_original, output_intervened\n",
    "    \n",
    "    def compute_causal_effect(self, x, layer_name, neuron_idx, intervention_values):\n",
    "        \"\"\"\n",
    "        Compute causal effect of neuron by sweeping intervention values.\n",
    "        \n",
    "        Returns:\n",
    "            Causal effect curve\n",
    "        \"\"\"\n",
    "        effects = []\n",
    "        \n",
    "        for value in intervention_values:\n",
    "            orig, interv = self.latent_surgery(x, layer_name, neuron_idx, value)\n",
    "            \n",
    "            # Measure effect (output difference)\n",
    "            effect = (interv - orig).abs().mean().item()\n",
    "            effects.append(effect)\n",
    "        \n",
    "        return np.array(effects)\n",
    "    \n",
    "    def synthetic_lesion(self, x, layer_name, neuron_indices):\n",
    "        \"\"\"\n",
    "        Ablate (zero out) specific neurons.\n",
    "        \n",
    "        Returns:\n",
    "            output_original, output_lesioned\n",
    "        \"\"\"\n",
    "        # Original\n",
    "        with torch.no_grad():\n",
    "            output_original = self.model(x)\n",
    "        \n",
    "        # Lesion hook\n",
    "        def lesion_hook(module, input, output):\n",
    "            output[:, neuron_indices] = 0\n",
    "            return output\n",
    "        \n",
    "        # Find and hook layer\n",
    "        target_layer = dict(self.model.named_modules())[layer_name]\n",
    "        handle = target_layer.register_forward_hook(lesion_hook)\n",
    "        \n",
    "        # Lesioned output\n",
    "        with torch.no_grad():\n",
    "            output_lesioned = self.model(x)\n",
    "        \n",
    "        handle.remove()\n",
    "        \n",
    "        return output_original, output_lesioned\n",
    "    \n",
    "    def identify_critical_neurons(self, x, layer_name, n_neurons=None):\n",
    "        \"\"\"\n",
    "        Identify which neurons are most critical (largest effect when ablated).\n",
    "        \"\"\"\n",
    "        # Get layer size\n",
    "        layer = dict(self.model.named_modules())[layer_name]\n",
    "        \n",
    "        # Test each neuron\n",
    "        effects = []\n",
    "        \n",
    "        if n_neurons is None:\n",
    "            # Try to infer from layer\n",
    "            if hasattr(layer, 'out_features'):\n",
    "                n_neurons = layer.out_features\n",
    "            else:\n",
    "                n_neurons = 10  # Default\n",
    "        \n",
    "        for neuron_idx in range(min(n_neurons, 20)):  # Limit to 20 for speed\n",
    "            orig, lesioned = self.synthetic_lesion(x, layer_name, [neuron_idx])\n",
    "            effect = (orig - lesioned).abs().mean().item()\n",
    "            effects.append(effect)\n",
    "        \n",
    "        return np.array(effects)\n",
    "\n",
    "print(\"Counterfactual analyzer implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple test model\n",
    "class TestNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(10, 20)\n",
    "        self.hidden2 = nn.Linear(20, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.hidden1(x))\n",
    "        x = torch.tanh(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Create model and analyzer\n",
    "test_model = TestNetwork()\n",
    "cf_analyzer = CounterfactualAnalyzer(test_model)\n",
    "\n",
    "# Test input\n",
    "x_test = torch.randn(5, 10)\n",
    "\n",
    "print(\"Test model created\")\n",
    "print(f\"  Input shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Latent surgery\n",
    "layer_name = 'hidden2'\n",
    "neuron_idx = 5\n",
    "intervention_values = np.linspace(-2, 2, 20)\n",
    "\n",
    "causal_effects = cf_analyzer.compute_causal_effect(\n",
    "    x_test, layer_name, neuron_idx, intervention_values\n",
    ")\n",
    "\n",
    "print(f\"\\nLatent surgery on {layer_name}, neuron {neuron_idx}:\")\n",
    "print(f\"  Causal effect range: {causal_effects.min():.4f} to {causal_effects.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Identify critical neurons\n",
    "critical_effects = cf_analyzer.identify_critical_neurons(x_test, 'hidden2', n_neurons=10)\n",
    "\n",
    "print(f\"\\nCritical neuron analysis:\")\n",
    "print(f\"  Tested {len(critical_effects)} neurons\")\n",
    "print(f\"  Most critical: neuron {np.argmax(critical_effects)} (effect={critical_effects.max():.4f})\")\n",
    "print(f\"  Least critical: neuron {np.argmin(critical_effects)} (effect={critical_effects.min():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize counterfactual analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Causal effect vs intervention value\n",
    "ax = axes[0]\n",
    "ax.plot(intervention_values, causal_effects, 'o-', linewidth=2, markersize=6)\n",
    "ax.set_xlabel('Intervention Value (neuron activation)')\n",
    "ax.set_ylabel('Causal Effect (output change)')\n",
    "ax.set_title(f'Causal Effect of Neuron {neuron_idx} in {layer_name}')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Critical neurons (lesion effects)\n",
    "ax = axes[1]\n",
    "neuron_indices = np.arange(len(critical_effects))\n",
    "colors = ['red' if e == critical_effects.max() else 'steelblue' \n",
    "         for e in critical_effects]\n",
    "ax.bar(neuron_indices, critical_effects, color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Neuron Index')\n",
    "ax.set_ylabel('Lesion Effect (output change when ablated)')\n",
    "ax.set_title('Critical Neuron Analysis (Red = most critical)')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Causal effect curve shows how output depends on neuron activation\")\n",
    "print(\"- Critical neurons have large effect when ablated\")\n",
    "print(\"- Non-critical neurons are redundant or less important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: The Complete Interpretability Toolkit\n",
    "\n",
    "### Journey Through 10 Notebooks\n",
    "\n",
    "Congratulations! You've mastered a comprehensive toolkit for mechanistic interpretability:\n",
    "\n",
    "1. **Introduction & Quickstart**: Foundation concepts, first SAE, first intervention\n",
    "2. **Sparse Autoencoders**: Decomposing polysemantic neurons into features\n",
    "3. **Causal Interventions**: Activation patching, ablations, circuit discovery\n",
    "4. **Fractal Analysis**: Biological realism through scale-free dynamics\n",
    "5. **Brain Alignment**: CCA, RSA, PLS for model-to-brain comparison\n",
    "6. **Dynamical Systems**: DMD, Lyapunov exponents, fixed points, dimensionality\n",
    "7. **Circuit Extraction**: Latent RNN models, DUNL, feature visualization\n",
    "8. **Biophysical Modeling**: Spiking networks, surrogate gradients, Dale's law\n",
    "9. **Information Theory**: Mutual information, information plane, MINE\n",
    "10. **Advanced Topics**: Meta-dynamics, manifold geometry, counterfactuals (this notebook!)\n",
    "\n",
    "### Key Principles\n",
    "\n",
    "1. **Sparsity enables interpretability**: SAEs decompose representations\n",
    "2. **Causality reveals mechanism**: Interventions, not correlations\n",
    "3. **Geometry reveals structure**: Manifolds, curvature, topology\n",
    "4. **Dynamics reveal computation**: How networks evolve, not just final state\n",
    "5. **Biological constraints help**: Dale's law, fractals, biophysical models\n",
    "6. **Information theory quantifies**: MI measures what networks know\n",
    "\n",
    "### Building Your Research Pipeline\n",
    "\n",
    "**For any project, combine**:\n",
    "1. **Feature extraction** (SAEs, circuits)\n",
    "2. **Causal analysis** (interventions, counterfactuals)\n",
    "3. **Geometric analysis** (manifolds, dimensionality)\n",
    "4. **Dynamical analysis** (training trajectories, fixed points)\n",
    "5. **Alignment** (brain recordings, behavior)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Apply to your models**: Use this toolkit on your research problems\n",
    "2. **Combine methods**: SAEs + interventions, fractals + alignment, etc.\n",
    "3. **Extend the toolkit**: Implement new methods from latest papers\n",
    "4. **Share discoveries**: Contribute to mechanistic interpretability community\n",
    "5. **Build standards**: Help make this a standard neuroscience toolkit\n",
    "\n",
    "### Vision: Community Resource\n",
    "\n",
    "The goal is for **neuros-mechint** to become:\n",
    "- Standard toolkit for neuroscience experiments worldwide\n",
    "- Community-driven resource with contributions from many researchers\n",
    "- Bridge between AI and neuroscience\n",
    "- Foundation for understanding intelligence\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "**Foundational papers**:\n",
    "- Olah et al. (2020): *Zoom In: An Introduction to Circuits*\n",
    "- Elhage et al. (2022): *Toy Models of Superposition*\n",
    "- Marks et al. (2024): *The Geometry of Truth*\n",
    "\n",
    "**Mechanistic interpretability resources**:\n",
    "- Anthropic's interpretability research\n",
    "- Distill.pub articles\n",
    "- NeuroAI reading group\n",
    "\n",
    "**Computational neuroscience**:\n",
    "- Dayan & Abbott: *Theoretical Neuroscience*\n",
    "- Gerstner et al.: *Neuronal Dynamics*\n",
    "\n",
    "---\n",
    "\n",
    "## Thank you for completing this journey!\n",
    "\n",
    "You now have the tools to:\n",
    "- Understand how neural networks compute\n",
    "- Extract interpretable circuits and features\n",
    "- Compare models to brains\n",
    "- Design more interpretable architectures\n",
    "- Contribute to understanding intelligence\n",
    "\n",
    "**The future of interpretability is bright, and you're part of it!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
