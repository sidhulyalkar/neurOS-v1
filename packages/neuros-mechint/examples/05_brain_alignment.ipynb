{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Alignment: Comparing Models to Brains\n",
    "\n",
    "**Quantifying how well artificial neural networks match biological neural activity**\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you'll master:\n",
    "1. **Canonical Correlation Analysis (CCA)** - Finding shared representational spaces\n",
    "2. **Representational Similarity Analysis (RSA)** - Comparing geometries without alignment\n",
    "3. **Partial Least Squares (PLS)** - Predictive alignment with latent variables\n",
    "4. **Statistical evaluation** - Noise ceilings, significance testing, confidence intervals\n",
    "5. **Multi-layer alignment** - Finding which model layers match brain regions\n",
    "6. **Practical workflows** - Complete analysis pipelines\n",
    "\n",
    "## The Central Question\n",
    "\n",
    "> **Do artificial neural networks process information like the brain?**\n",
    "\n",
    "To answer this, we need rigorous methods to compare model representations with brain recordings (fMRI, EEG, MEG, neural recordings).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Notebooks 01-04\n",
    "- Understanding of linear algebra\n",
    "- Familiarity with neuroscience recordings (helpful but not required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA as SklearnCCA, PLSRegression\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Note: Some alignment tools require sklearn\n",
    "try:\n",
    "    from neuros_mechint.alignment import CCA, RSA, PLS\n",
    "    print(\"neuros-mechint alignment tools available\")\n",
    "except ImportError:\n",
    "    print(\"Using sklearn implementations (neuros-mechint alignment optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Problem\n",
    "\n",
    "### Why Compare Models to Brains?\n",
    "\n",
    "**For Neuroscience:**\n",
    "- Validate that models use brain-like computations\n",
    "- Test hypotheses about neural coding\n",
    "- Predict neural responses to new stimuli\n",
    "- Understand information processing hierarchies\n",
    "\n",
    "**For AI:**\n",
    "- Guide architecture design toward biological plausibility\n",
    "- Discover computational principles that work in nature\n",
    "- Improve robustness and generalization\n",
    "- Enable brain-computer interfaces\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Models and brains differ in many ways:\n",
    "- **Different representations**: Model features vs neural activity patterns\n",
    "- **Different dimensions**: 1000s of neurons vs 1000s of model units\n",
    "- **Different scales**: ms (neurons) vs sec (fMRI)\n",
    "- **Different noise**: Neural variability vs computational determinism\n",
    "\n",
    "We need methods that can compare despite these differences!\n",
    "\n",
    "### Three Complementary Approaches\n",
    "\n",
    "1. **CCA**: Find linear transformations that maximize correlation\n",
    "   - \"What shared information do model and brain encode?\"\n",
    "   - Linear alignment required\n",
    "\n",
    "2. **RSA**: Compare pairwise similarity structures\n",
    "   - \"Do model and brain have similar representational geometries?\"\n",
    "   - No alignment needed!\n",
    "\n",
    "3. **PLS**: Predict brain activity from model\n",
    "   - \"Can we use the model to predict brain responses?\"\n",
    "   - Predictive modeling\n",
    "\n",
    "Let's explore each!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Canonical Correlation Analysis (CCA)\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "CCA finds linear projections that maximize correlation between two datasets.\n",
    "\n",
    "**Mathematical Setup:**\n",
    "\n",
    "Given:\n",
    "- Model representations: $X \\in \\mathbb{R}^{n \\times p}$ (n stimuli, p model features)\n",
    "- Brain responses: $Y \\in \\mathbb{R}^{n \\times q}$ (n stimuli, q brain features)\n",
    "\n",
    "Find:\n",
    "- Projections $a, b$ such that $\\text{corr}(Xa, Yb)$ is maximized\n",
    "\n",
    "**Result:**\n",
    "- Canonical correlations: $\\rho_1 \\geq \\rho_2 \\geq ... \\geq \\rho_k$\n",
    "- Canonical variates: Transformed representations in shared space\n",
    "\n",
    "### Implementing CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic \"brain\" and \"model\" data\n",
    "n_stimuli = 100\n",
    "n_model_features = 50\n",
    "n_brain_features = 80\n",
    "\n",
    "# Create some shared structure\n",
    "shared_signal = np.random.randn(n_stimuli, 10)  # 10 shared dimensions\n",
    "\n",
    "# Model representations (shared + specific)\n",
    "model_specific = np.random.randn(n_stimuli, n_model_features - 10) * 0.5\n",
    "model_data = np.concatenate([shared_signal, model_specific], axis=1)\n",
    "\n",
    "# Brain representations (shared + specific + noise)\n",
    "brain_specific = np.random.randn(n_stimuli, n_brain_features - 10) * 0.5\n",
    "brain_noise = np.random.randn(n_stimuli, n_brain_features) * 0.3\n",
    "brain_data = np.concatenate([shared_signal, brain_specific], axis=1) + brain_noise\n",
    "\n",
    "print(f\"Model data: {model_data.shape}\")\n",
    "print(f\"Brain data: {brain_data.shape}\")\n",
    "print(f\"Shared dimensions: 10 (ground truth)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform CCA\n",
    "n_components = 20\n",
    "\n",
    "cca = SklearnCCA(n_components=n_components)\n",
    "cca.fit(model_data, brain_data)\n",
    "\n",
    "# Transform to canonical space\n",
    "model_canonical, brain_canonical = cca.transform(model_data, brain_data)\n",
    "\n",
    "# Compute canonical correlations\n",
    "canonical_corrs = [np.corrcoef(model_canonical[:, i], brain_canonical[:, i])[0, 1] \n",
    "                   for i in range(n_components)]\n",
    "\n",
    "print(\"\\nCanonical Correlations:\")\n",
    "for i, corr in enumerate(canonical_corrs[:10]):\n",
    "    print(f\"  Component {i+1}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing CCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Top-left: Canonical correlations\n",
    "axes[0, 0].bar(range(1, n_components+1), canonical_corrs)\n",
    "axes[0, 0].axhline(0.5, color='red', linestyle='--', alpha=0.5, label='Threshold')\n",
    "axes[0, 0].set_xlabel('Canonical Component')\n",
    "axes[0, 0].set_ylabel('Correlation')\n",
    "axes[0, 0].set_title('Canonical Correlations')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top-right: Scree plot\n",
    "cumsum_corrs = np.cumsum(canonical_corrs) / np.sum(canonical_corrs)\n",
    "axes[0, 1].plot(range(1, n_components+1), cumsum_corrs, 'o-', linewidth=2)\n",
    "axes[0, 1].axhline(0.9, color='green', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "axes[0, 1].set_xlabel('Number of Components')\n",
    "axes[0, 1].set_ylabel('Cumulative Sum of Correlations (normalized)')\n",
    "axes[0, 1].set_title('Cumulative Canonical Correlations')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom-left: First canonical component scatter\n",
    "axes[1, 0].scatter(model_canonical[:, 0], brain_canonical[:, 0], alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Model Canonical Variable 1')\n",
    "axes[1, 0].set_ylabel('Brain Canonical Variable 1')\n",
    "axes[1, 0].set_title(f'First Canonical Component (r={canonical_corrs[0]:.3f})')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(model_canonical[:, 0], brain_canonical[:, 0], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1, 0].plot(model_canonical[:, 0], p(model_canonical[:, 0]), \n",
    "                \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "# Bottom-right: Second canonical component\n",
    "axes[1, 1].scatter(model_canonical[:, 1], brain_canonical[:, 1], alpha=0.6, color='orange')\n",
    "axes[1, 1].set_xlabel('Model Canonical Variable 2')\n",
    "axes[1, 1].set_ylabel('Brain Canonical Variable 2')\n",
    "axes[1, 1].set_title(f'Second Canonical Component (r={canonical_corrs[1]:.3f})')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "z = np.polyfit(model_canonical[:, 1], brain_canonical[:, 1], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1, 1].plot(model_canonical[:, 1], p(model_canonical[:, 1]), \n",
    "                \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ CCA successfully found {sum(np.array(canonical_corrs) > 0.5)} \"\n",
    "      f\"strong canonical dimensions (r > 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting CCA Results\n",
    "\n",
    "**Strong correlations (r > 0.7)**: Shared information between model and brain\n",
    "\n",
    "**Moderate correlations (0.4 < r < 0.7)**: Partially shared representations\n",
    "\n",
    "**Weak correlations (r < 0.4)**: Little shared structure\n",
    "\n",
    "**Key insight**: The first few canonical components capture the most shared variance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Representational Similarity Analysis (RSA)\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "RSA compares the **geometry** of representations without requiring alignment.\n",
    "\n",
    "**Method**:\n",
    "1. Compute Representational Dissimilarity Matrix (RDM) for model\n",
    "2. Compute RDM for brain\n",
    "3. Compare the two RDMs\n",
    "\n",
    "**RDM**: Matrix where $RDM_{ij} = d(stimulus_i, stimulus_j)$\n",
    "\n",
    "**Why RSA?**\n",
    "- No alignment needed\n",
    "- Scale invariant\n",
    "- Captures second-order structure\n",
    "- Works across different measurement types\n",
    "\n",
    "### Computing RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdm(data, metric='correlation'):\n",
    "    \"\"\"\n",
    "    Compute Representational Dissimilarity Matrix.\n",
    "    \n",
    "    Args:\n",
    "        data: (n_stimuli, n_features)\n",
    "        metric: 'correlation', 'euclidean', 'cosine'\n",
    "    \n",
    "    Returns:\n",
    "        RDM: (n_stimuli, n_stimuli)\n",
    "    \"\"\"\n",
    "    if metric == 'correlation':\n",
    "        # 1 - correlation = dissimilarity\n",
    "        rdm = 1 - np.corrcoef(data)\n",
    "    else:\n",
    "        rdm = squareform(pdist(data, metric=metric))\n",
    "    \n",
    "    return rdm\n",
    "\n",
    "# Compute RDMs\n",
    "model_rdm = compute_rdm(model_data, metric='correlation')\n",
    "brain_rdm = compute_rdm(brain_data, metric='correlation')\n",
    "\n",
    "print(f\"Model RDM: {model_rdm.shape}\")\n",
    "print(f\"Brain RDM: {brain_rdm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RDMs\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Model RDM\n",
    "im1 = axes[0].imshow(model_rdm, cmap='viridis', aspect='auto')\n",
    "axes[0].set_title('Model RDM')\n",
    "axes[0].set_xlabel('Stimulus')\n",
    "axes[0].set_ylabel('Stimulus')\n",
    "plt.colorbar(im1, ax=axes[0], label='Dissimilarity')\n",
    "\n",
    "# Brain RDM\n",
    "im2 = axes[1].imshow(brain_rdm, cmap='viridis', aspect='auto')\n",
    "axes[1].set_title('Brain RDM')\n",
    "axes[1].set_xlabel('Stimulus')\n",
    "axes[1].set_ylabel('Stimulus')\n",
    "plt.colorbar(im2, ax=axes[1], label='Dissimilarity')\n",
    "\n",
    "# Difference\n",
    "diff = np.abs(model_rdm - brain_rdm)\n",
    "im3 = axes[2].imshow(diff, cmap='RdYlGn_r', aspect='auto')\n",
    "axes[2].set_title('Absolute Difference')\n",
    "axes[2].set_xlabel('Stimulus')\n",
    "axes[2].set_ylabel('Stimulus')\n",
    "plt.colorbar(im3, ax=axes[2], label='|Model - Brain|')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RDMs using correlation\n",
    "# Extract upper triangular (excluding diagonal)\n",
    "mask = np.triu(np.ones_like(model_rdm, dtype=bool), k=1)\n",
    "model_rdm_vec = model_rdm[mask]\n",
    "brain_rdm_vec = brain_rdm[mask]\n",
    "\n",
    "# Compute Spearman correlation (rank-based, robust)\n",
    "spearman_rho, spearman_p = spearmanr(model_rdm_vec, brain_rdm_vec)\n",
    "\n",
    "# Compute Pearson correlation\n",
    "pearson_r, pearson_p = pearsonr(model_rdm_vec, brain_rdm_vec)\n",
    "\n",
    "print(\"RSA Similarity Scores:\")\n",
    "print(f\"  Spearman ρ = {spearman_rho:.3f} (p = {spearman_p:.2e})\")\n",
    "print(f\"  Pearson r  = {pearson_r:.3f} (p = {pearson_p:.2e})\")\n",
    "\n",
    "# Visualize scatter\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(model_rdm_vec, brain_rdm_vec, alpha=0.3, s=10)\n",
    "plt.xlabel('Model Dissimilarity')\n",
    "plt.ylabel('Brain Dissimilarity')\n",
    "plt.title(f'RDM Comparison (Spearman ρ = {spearman_rho:.3f})')\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(model_rdm_vec, brain_rdm_vec, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(model_rdm_vec.min(), model_rdm_vec.max(), 100)\n",
    "plt.plot(x_line, p(x_line), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "if spearman_rho > 0.5:\n",
    "    print(\"\\n✅ Strong representational similarity! Model and brain have similar geometry.\")\n",
    "elif spearman_rho > 0.3:\n",
    "    print(\"\\n⚠️  Moderate similarity. Some shared structure.\")\n",
    "else:\n",
    "    print(\"\\n❌ Weak similarity. Different representational geometries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Partial Least Squares (PLS)\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "PLS finds latent variables that maximize covariance and can predict brain activity from model.\n",
    "\n",
    "**Advantages**:\n",
    "- Handles multivariate output (many brain features)\n",
    "- Finds latent structure\n",
    "- Predictive (can test on new data)\n",
    "- Works well with high-dimensional data\n",
    "\n",
    "**Mathematical Setup**:\n",
    "\n",
    "Find projections $t = Xw$ and $u = Yc$ such that $\\text{cov}(t, u)$ is maximized.\n",
    "\n",
    "### Implementing PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test\n",
    "n_train = 80\n",
    "train_idx = np.arange(n_train)\n",
    "test_idx = np.arange(n_train, n_stimuli)\n",
    "\n",
    "model_train = model_data[train_idx]\n",
    "model_test = model_data[test_idx]\n",
    "brain_train = brain_data[train_idx]\n",
    "brain_test = brain_data[test_idx]\n",
    "\n",
    "# Fit PLS\n",
    "n_components_pls = 15\n",
    "pls = PLSRegression(n_components=n_components_pls)\n",
    "pls.fit(model_train, brain_train)\n",
    "\n",
    "# Predict brain activity\n",
    "brain_pred_train = pls.predict(model_train)\n",
    "brain_pred_test = pls.predict(model_test)\n",
    "\n",
    "# Compute R² scores\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_train = r2_score(brain_train, brain_pred_train)\n",
    "r2_test = r2_score(brain_test, brain_pred_test)\n",
    "\n",
    "print(\"PLS Prediction Performance:\")\n",
    "print(f\"  Training R²: {r2_train:.3f}\")\n",
    "print(f\"  Test R²:     {r2_test:.3f}\")\n",
    "print(f\"\\n  Using {n_components_pls} latent components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Plot first 3 brain features\n",
    "for i in range(3):\n",
    "    # Training\n",
    "    axes[0, i].scatter(brain_train[:, i], brain_pred_train[:, i], alpha=0.6)\n",
    "    axes[0, i].plot([brain_train[:, i].min(), brain_train[:, i].max()],\n",
    "                    [brain_train[:, i].min(), brain_train[:, i].max()],\n",
    "                    'r--', linewidth=2)\n",
    "    axes[0, i].set_xlabel(f'True Brain Feature {i+1}')\n",
    "    axes[0, i].set_ylabel(f'Predicted')\n",
    "    axes[0, i].set_title(f'Training (Feature {i+1})')\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Test\n",
    "    axes[1, i].scatter(brain_test[:, i], brain_pred_test[:, i], alpha=0.6, color='orange')\n",
    "    axes[1, i].plot([brain_test[:, i].min(), brain_test[:, i].max()],\n",
    "                    [brain_test[:, i].min(), brain_test[:, i].max()],\n",
    "                    'r--', linewidth=2)\n",
    "    axes[1, i].set_xlabel(f'True Brain Feature {i+1}')\n",
    "    axes[1, i].set_ylabel(f'Predicted')\n",
    "    axes[1, i].set_title(f'Test (Feature {i+1})')\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Statistical Evaluation\n",
    "\n",
    "### Noise Ceiling\n",
    "\n",
    "The **noise ceiling** estimates the maximum achievable performance given measurement noise.\n",
    "\n",
    "**Why it matters**: If brain data has 30% noise, you can't achieve 100% prediction!\n",
    "\n",
    "**Method**: Split-half reliability\n",
    "1. Split brain recordings into two halves\n",
    "2. Correlate the two halves\n",
    "3. This gives upper bound on explainable variance\n",
    "\n",
    "### Computing Noise Ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_noise_ceiling(data, n_splits=10):\n",
    "    \"\"\"\n",
    "    Estimate noise ceiling via split-half correlation.\n",
    "    \n",
    "    Args:\n",
    "        data: (n_stimuli, n_features) - with repetitions\n",
    "        n_splits: number of random splits\n",
    "    \n",
    "    Returns:\n",
    "        noise_ceiling: upper bound on explainable variance\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    \n",
    "    for _ in range(n_splits):\n",
    "        # Random split\n",
    "        perm = np.random.permutation(data.shape[0])\n",
    "        half1 = data[perm[:len(perm)//2]]\n",
    "        half2 = data[perm[len(perm)//2:]]\n",
    "        \n",
    "        # Average across features\n",
    "        mean_corr = np.mean([np.corrcoef(half1[:, i], half2[:min(len(half1), len(half2)), i])[0, 1]\n",
    "                            for i in range(min(half1.shape[1], half2.shape[1]))])\n",
    "        correlations.append(mean_corr)\n",
    "    \n",
    "    # Spearman-Brown correction for full data\n",
    "    mean_corr = np.mean(correlations)\n",
    "    noise_ceiling = 2 * mean_corr / (1 + mean_corr)\n",
    "    \n",
    "    return noise_ceiling, correlations\n",
    "\n",
    "# Estimate noise ceiling\n",
    "noise_ceiling, split_corrs = estimate_noise_ceiling(brain_data, n_splits=20)\n",
    "\n",
    "print(f\"Noise Ceiling Estimate: {noise_ceiling:.3f}\")\n",
    "print(f\"This means at most {noise_ceiling*100:.1f}% of variance is explainable\")\n",
    "\n",
    "# Normalize our scores\n",
    "normalized_cca = canonical_corrs[0] / noise_ceiling\n",
    "normalized_rsa = spearman_rho / noise_ceiling\n",
    "normalized_pls = r2_test / noise_ceiling\n",
    "\n",
    "print(f\"\\nNormalized Scores (fraction of explainable variance):\")\n",
    "print(f\"  CCA: {normalized_cca:.2%}\")\n",
    "print(f\"  RSA: {normalized_rsa:.2%}\")\n",
    "print(f\"  PLS: {normalized_pls:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals via Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data1, data2, metric_fn, n_bootstrap=1000, ci=95):\n",
    "    \"\"\"\n",
    "    Compute confidence interval via bootstrapping.\n",
    "    \n",
    "    Args:\n",
    "        data1, data2: datasets to compare\n",
    "        metric_fn: function(data1, data2) -> score\n",
    "        n_bootstrap: number of bootstrap samples\n",
    "        ci: confidence interval percentage\n",
    "    \n",
    "    Returns:\n",
    "        (lower, upper, mean, std)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    n = len(data1)\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        score = metric_fn(data1[idx], data2[idx])\n",
    "        scores.append(score)\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    lower = np.percentile(scores, (100-ci)/2)\n",
    "    upper = np.percentile(scores, 100 - (100-ci)/2)\n",
    "    \n",
    "    return lower, upper, np.mean(scores), np.std(scores)\n",
    "\n",
    "# Bootstrap CCA\n",
    "def cca_metric(X, Y):\n",
    "    cca_temp = SklearnCCA(n_components=1)\n",
    "    cca_temp.fit(X, Y)\n",
    "    X_c, Y_c = cca_temp.transform(X, Y)\n",
    "    return np.corrcoef(X_c[:, 0], Y_c[:, 0])[0, 1]\n",
    "\n",
    "print(\"Computing bootstrap confidence intervals...\")\n",
    "lower, upper, mean, std = bootstrap_ci(model_data, brain_data, cca_metric, n_bootstrap=100)\n",
    "\n",
    "print(f\"\\nCCA Score: {mean:.3f} ± {std:.3f}\")\n",
    "print(f\"95% CI: [{lower:.3f}, {upper:.3f}]\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(['CCA', 'RSA (Spearman)', 'PLS (R²)'], \n",
    "        [canonical_corrs[0], spearman_rho, r2_test],\n",
    "        yerr=[[canonical_corrs[0]-lower], [0.05], [0.08]],  # Approximate for demo\n",
    "        capsize=10, edgecolor='black', alpha=0.7)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Brain Alignment Scores with Confidence Intervals')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Multi-Layer Alignment\n",
    "\n",
    "### Finding Which Layers Match Brain Regions\n",
    "\n",
    "Different model layers may align with different brain regions. Let's find the best matches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple multi-layer model\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 30)\n",
    "        self.layer2 = nn.Linear(30, 50)\n",
    "        self.layer3 = nn.Linear(50, 40)\n",
    "    \n",
    "    def forward(self, x, return_all=False):\n",
    "        h1 = torch.relu(self.layer1(x))\n",
    "        h2 = torch.relu(self.layer2(h1))\n",
    "        h3 = self.layer3(h2)\n",
    "        \n",
    "        if return_all:\n",
    "            return {'layer1': h1, 'layer2': h2, 'layer3': h3}\n",
    "        return h3\n",
    "\n",
    "model = SimpleNetwork()\n",
    "\n",
    "# Generate activations for all layers\n",
    "inputs = torch.randn(n_stimuli, 10)\n",
    "with torch.no_grad():\n",
    "    layer_acts = model(inputs, return_all=True)\n",
    "\n",
    "# Convert to numpy\n",
    "layer_acts_np = {k: v.numpy() for k, v in layer_acts.items()}\n",
    "\n",
    "print(\"Layer shapes:\")\n",
    "for layer, acts in layer_acts_np.items():\n",
    "    print(f\"  {layer}: {acts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute alignment for each layer\n",
    "layer_alignments = {}\n",
    "\n",
    "for layer_name, acts in layer_acts_np.items():\n",
    "    # CCA alignment\n",
    "    cca_temp = SklearnCCA(n_components=min(10, acts.shape[1], brain_data.shape[1]))\n",
    "    cca_temp.fit(acts, brain_data)\n",
    "    X_c, Y_c = cca_temp.transform(acts, brain_data)\n",
    "    cca_score = np.corrcoef(X_c[:, 0], Y_c[:, 0])[0, 1]\n",
    "    \n",
    "    # RSA alignment\n",
    "    layer_rdm = compute_rdm(acts)\n",
    "    mask = np.triu(np.ones_like(layer_rdm, dtype=bool), k=1)\n",
    "    rsa_score, _ = spearmanr(layer_rdm[mask], brain_rdm[mask])\n",
    "    \n",
    "    layer_alignments[layer_name] = {\n",
    "        'cca': cca_score,\n",
    "        'rsa': rsa_score\n",
    "    }\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "layers = list(layer_alignments.keys())\n",
    "cca_scores = [layer_alignments[l]['cca'] for l in layers]\n",
    "rsa_scores = [layer_alignments[l]['rsa'] for l in layers]\n",
    "\n",
    "# CCA scores\n",
    "axes[0].bar(layers, cca_scores, edgecolor='black')\n",
    "axes[0].set_ylabel('CCA Score')\n",
    "axes[0].set_title('CCA Alignment Across Layers')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RSA scores\n",
    "axes[1].bar(layers, rsa_scores, edgecolor='black', color='orange')\n",
    "axes[1].set_ylabel('RSA Score (Spearman ρ)')\n",
    "axes[1].set_title('RSA Alignment Across Layers')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best layer\n",
    "best_cca_layer = max(layer_alignments.items(), key=lambda x: x[1]['cca'])[0]\n",
    "best_rsa_layer = max(layer_alignments.items(), key=lambda x: x[1]['rsa'])[0]\n",
    "\n",
    "print(f\"\\nBest aligned layers:\")\n",
    "print(f\"  CCA: {best_cca_layer} (score: {layer_alignments[best_cca_layer]['cca']:.3f})\")\n",
    "print(f\"  RSA: {best_rsa_layer} (score: {layer_alignments[best_rsa_layer]['rsa']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Complete Alignment Pipeline\n",
    "\n",
    "Let's put it all together in a reusable pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainAlignmentPipeline:\n",
    "    \"\"\"\n",
    "    Complete pipeline for model-to-brain alignment analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=20):\n",
    "        self.n_components = n_components\n",
    "        self.results = {}\n",
    "    \n",
    "    def run_cca(self, model_data, brain_data):\n",
    "        \"\"\"Canonical Correlation Analysis\"\"\"\n",
    "        cca = SklearnCCA(n_components=self.n_components)\n",
    "        cca.fit(model_data, brain_data)\n",
    "        X_c, Y_c = cca.transform(model_data, brain_data)\n",
    "        \n",
    "        corrs = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] \n",
    "                for i in range(self.n_components)]\n",
    "        \n",
    "        self.results['cca'] = {\n",
    "            'correlations': corrs,\n",
    "            'top_correlation': corrs[0],\n",
    "            'mean_correlation': np.mean(corrs)\n",
    "        }\n",
    "    \n",
    "    def run_rsa(self, model_data, brain_data):\n",
    "        \"\"\"Representational Similarity Analysis\"\"\"\n",
    "        model_rdm = compute_rdm(model_data)\n",
    "        brain_rdm = compute_rdm(brain_data)\n",
    "        \n",
    "        mask = np.triu(np.ones_like(model_rdm, dtype=bool), k=1)\n",
    "        rho, p = spearmanr(model_rdm[mask], brain_rdm[mask])\n",
    "        \n",
    "        self.results['rsa'] = {\n",
    "            'spearman_rho': rho,\n",
    "            'p_value': p\n",
    "        }\n",
    "    \n",
    "    def run_pls(self, model_data, brain_data, test_size=0.2):\n",
    "        \"\"\"Partial Least Squares\"\"\"\n",
    "        n_train = int(len(model_data) * (1 - test_size))\n",
    "        \n",
    "        pls = PLSRegression(n_components=self.n_components)\n",
    "        pls.fit(model_data[:n_train], brain_data[:n_train])\n",
    "        \n",
    "        pred_train = pls.predict(model_data[:n_train])\n",
    "        pred_test = pls.predict(model_data[n_train:])\n",
    "        \n",
    "        r2_train = r2_score(brain_data[:n_train], pred_train)\n",
    "        r2_test = r2_score(brain_data[n_train:], pred_test)\n",
    "        \n",
    "        self.results['pls'] = {\n",
    "            'r2_train': r2_train,\n",
    "            'r2_test': r2_test\n",
    "        }\n",
    "    \n",
    "    def run_full_analysis(self, model_data, brain_data):\n",
    "        \"\"\"Run complete analysis pipeline\"\"\"\n",
    "        print(\"Running complete brain alignment analysis...\\n\")\n",
    "        \n",
    "        print(\"1. Canonical Correlation Analysis...\")\n",
    "        self.run_cca(model_data, brain_data)\n",
    "        \n",
    "        print(\"2. Representational Similarity Analysis...\")\n",
    "        self.run_rsa(model_data, brain_data)\n",
    "        \n",
    "        print(\"3. Partial Least Squares...\")\n",
    "        self.run_pls(model_data, brain_data)\n",
    "        \n",
    "        self.print_report()\n",
    "    \n",
    "    def print_report(self):\n",
    "        \"\"\"Print formatted results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BRAIN ALIGNMENT REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\n📊 CCA Results:\")\n",
    "        print(f\"  Top correlation:  {self.results['cca']['top_correlation']:.3f}\")\n",
    "        print(f\"  Mean correlation: {self.results['cca']['mean_correlation']:.3f}\")\n",
    "        \n",
    "        print(\"\\n📐 RSA Results:\")\n",
    "        print(f\"  Spearman ρ: {self.results['rsa']['spearman_rho']:.3f}\")\n",
    "        print(f\"  p-value:    {self.results['rsa']['p_value']:.2e}\")\n",
    "        \n",
    "        print(\"\\n🎯 PLS Results:\")\n",
    "        print(f\"  Training R²: {self.results['pls']['r2_train']:.3f}\")\n",
    "        print(f\"  Test R²:     {self.results['pls']['r2_test']:.3f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Run pipeline\n",
    "pipeline = BrainAlignmentPipeline(n_components=15)\n",
    "pipeline.run_full_analysis(model_data, brain_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### What You've Mastered\n",
    "\n",
    "1. ✓ **CCA** - Finding shared representational spaces via linear alignment\n",
    "2. ✓ **RSA** - Comparing representational geometries without alignment\n",
    "3. ✓ **PLS** - Predicting brain activity from model representations\n",
    "4. ✓ **Statistical evaluation** - Noise ceilings, confidence intervals\n",
    "5. ✓ **Multi-layer analysis** - Finding which layers match brain regions\n",
    "6. ✓ **Complete pipelines** - End-to-end alignment workflows\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**When to use each method:**\n",
    "- **CCA**: When you want linear alignment and care about correlations\n",
    "- **RSA**: When you care about geometry and don't want to assume linearity\n",
    "- **PLS**: When you want to predict brain activity from models\n",
    "\n",
    "**Always remember:**\n",
    "- Normalize by noise ceiling for fair comparison\n",
    "- Use cross-validation for PLS\n",
    "- Test statistical significance\n",
    "- Compare multiple layers to find best matches\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "You can now:\n",
    "- Compare vision models to V1, V4, IT cortex\n",
    "- Test if language models align with language areas\n",
    "- Validate model architectures against brain data\n",
    "- Predict neural responses to novel stimuli\n",
    "- Guide model development toward biological plausibility\n",
    "\n",
    "### Next Notebook\n",
    "\n",
    "**[06_dynamical_systems.ipynb](06_dynamical_systems.ipynb)**\n",
    "\n",
    "Learn to analyze neural trajectories using:\n",
    "- Koopman operator theory\n",
    "- Lyapunov exponents\n",
    "- Fixed point analysis\n",
    "- Controllability\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "**Essential Papers**:\n",
    "1. Kriegeskorte et al. (2008): \"Representational Similarity Analysis\"\n",
    "2. Yamins & DiCarlo (2016): \"Using goal-driven deep learning models to understand sensory cortex\"\n",
    "3. Schrimpf et al. (2020): \"Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?\"\n",
    "4. Nastase et al. (2019): \"Measuring shared responses across subjects using intersubject correlation\"\n",
    "\n",
    "---\n",
    "\n",
    "**Excellent work!** You can now rigorously compare artificial and biological neural networks! 🧠🤖"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
